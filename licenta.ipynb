{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giann\\anaconda3\\envs\\tf_best\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from extra_keras_datasets import emnist\n",
    "from skimage import transform\n",
    "from tensorflow.keras.models import load_model\n",
    "import datetime \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unflatten_images(images:np.array, width:int, height:int):\n",
    "    \"\"\"\n",
    "    This method will reshape each flatten image to a square like image.\n",
    "\n",
    "    Args:\n",
    "        images (np.array): array of flatten images\n",
    "\n",
    "    Returns:\n",
    "        (np.array,np.array)\n",
    "    \"\"\"\n",
    "\n",
    "    unflatten_images = images.reshape((len(images), width, height, 1))\n",
    "    transposed_unflatten_images= np.transpose(unflatten_images, (0, 2, 1, 3))\n",
    "\n",
    "    return transposed_unflatten_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emnist_data(path:str = \"no_path\"):\n",
    "    \"\"\"\n",
    "    Method to load data wheter from a path to a csv file or from the extra_kagle_datasets.\n",
    "\n",
    "    Args:\n",
    "        path (str, optional): Path if we want to load data from csv. Defaults to \"no_path\".\n",
    "\n",
    "    Returns:\n",
    "        (np.array,np.array,np.array,np.array): train_images, encoded_train_labels, test_images, encoded_test_labels\n",
    "    \"\"\"\n",
    "\n",
    "    if path == \"no_path\":\n",
    "        (train_images, train_labels), (test_images, test_labels) =  emnist.load_data()\n",
    "\n",
    "\n",
    "        train_images=np.reshape(train_images, [len(train_images),28,28, 1]) \n",
    "        test_images=np.reshape(test_images, [len(test_images),28,28, 1] ) \n",
    "\n",
    "    else:\n",
    "        train_path = os.path.join(path,\"emnist-balanced-train.csv\")\n",
    "        test_path = os.path.join(path,\"emnist-balanced-test.csv\" )\n",
    "\n",
    "        train_data = np.array(pd.read_csv(train_path))\n",
    "        test_data = np.array(pd.read_csv(test_path))\n",
    "\n",
    "        train_images = unflatten_images(train_data[:,1:],\n",
    "                                                      28,\n",
    "                                                      28)\n",
    "        test_images = unflatten_images(test_data[:, 1:],\n",
    "                                                    28,\n",
    "                                                    28)\n",
    "        train_labels = train_data[:, :1]\n",
    "        test_labels = test_data[:, :1]\n",
    "    \n",
    "    encoded_train_labels = tf.keras.utils.to_categorical(train_labels, 47)\n",
    "    encoded_test_labels = tf.keras.utils.to_categorical(test_labels, 47)\n",
    "\n",
    "    train_images = train_images.astype('float32') / 255\n",
    "    test_images = test_images.astype('float32') / 255\n",
    "    \n",
    "    print(f\"Train data is of shape: {train_images.shape}\")\n",
    "    print(f\"Train labels is of shape: {train_labels.shape}\")\n",
    "    print(f\"Test data is of shape: {test_images.shape}\")\n",
    "    print(f\"Test labels is of shape: {test_labels.shape}\")\n",
    "\n",
    "    return train_images, encoded_train_labels, test_images, encoded_test_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading train data from csv file of the emnist balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data is of shape: (112799, 28, 28, 1)\n",
      "Train labels is of shape: (112799, 1)\n",
      "Test data is of shape: (18799, 28, 28, 1)\n",
      "Test labels is of shape: (18799, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, test_images, test_labels = get_emnist_data('Z:/Master I/PML - Practical Machine Learning/Jiani/data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading train data from  keras extended datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading dataset = emnist\n",
      "WARNING:root:Please cite the following paper when using or referencing this Extra Keras Dataset:\n",
      "WARNING:root:Cohen, G., Afshar, S., Tapson, J., & van Schaik, A. (2017). EMNIST: an extension of MNIST to handwritten letters. Retrieved from http://arxiv.org/abs/1702.05373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data is of shape: (112800, 28, 28, 1)\n",
      "Train labels is of shape: (112800,)\n",
      "Test data is of shape: (18800, 28, 28, 1)\n",
      "Test labels is of shape: (18800,)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, test_images, test_labels = get_emnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, nr_of_images: int):\n",
    "    \"\"\"\n",
    "    Method used to plot some images after loading in order to check if the images we're loaded correctly.\n",
    "\n",
    "    Args:\n",
    "        images (np.array): Loaded images\n",
    "        nr_of_images (int): Number of images to show (it should be a squared number)\n",
    "    \"\"\"\n",
    "    nr_of_images_per_axe = int(np.sqrt(nr_of_images))\n",
    "    _, axs = plt.subplots(nr_of_images_per_axe, nr_of_images_per_axe, figsize=(5, 5))\n",
    "    axs = axs.flatten()\n",
    "    for img, ax in zip(images, axs):\n",
    "        ax.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAGwCAYAAADMu+AXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABYMUlEQVR4nO3deXxU1fk/8GcmmUyAJBOSkIQQBiK7giKRQAT9oY1SaK0obtUqWpWiiRXR2m+oS21t862tlaos37qAtiJKFai0RWuiIBq2SFS2uEUIywxrFhKyzMz5/YFGP+eGDJNMMnOTz/v1yh/PzJ07JzNP7sm9zz3nWJRSSoiIiEzKGuoGEBERtQc7MiIiMjV2ZEREZGrsyIiIyNTYkRERkamxIyMiIlNjR0ZERKbGjoyIiEyNHRkREZkaOzIiIjK1DuvI5s+fLwMHDpTo6GgZN26cbNq0qaPeikyKOUKtYX7Q6bJ0xFyLr7zyitx0002yaNEiGTdunMybN0+WL18uZWVlkpyc3OprfT6f7N+/X2JjY8VisQS7adRJlFJSU1MjaWlpYrUa/19ijnRvHZkfIsyRrsBfjugbB11WVpbKzc1tjr1er0pLS1MFBQV+X1tRUaFEhD9d5KeiooI5wp9OzQ/mSNf6OVWOfFekBFljY6OUlJRIfn5+82NWq1VycnKkuLjYsH1DQ4M0NDQ0x+rrE8SJMlUixRbs5lEn8UiTrJd/S2xsrOE55ggFMz9EmCNdUWs5ogt6R3b48GHxer2SkpICj6ekpMiuXbsM2xcUFMgjjzzSQsNsEmlhAprWyeNIi5d1mCMUzPwQYY50Sa3kiC7kdy3m5+dLVVVV809FRUWom0RhhjlC/jBHuregn5ElJSVJRESEuN1ueNztdktqaqphe7vdLna7PdjNoDDGHKHWBJofIsyR02aNgNASgbHyenF7nxaHqaCfkUVFRUlmZqYUFhY2P+bz+aSwsFCys7OD/XZkQswRag3zgwIV9DMyEZE5c+bIjBkz5LzzzpOsrCyZN2+e1NbWyi233NIRb0cmxByh1jA/KBAd0pFde+21cujQIXnooYfE5XLJ6NGjZc2aNYbiLXVfzBFqDfODAtEhA6Lbo7q6WhwOh0ySy7vW3UbanTfWHj3w6Yz+rb7c9/lXEKvv3GocjjyqSd6VVVJVVSVxcXFB3Xd3yZHIfmkQe/vEt/pya6MHYrVnP8b1gedMR9VMOjI/RLpujlhsURB7x50J8YEJPSFuisPDe1Im1h1vdG6EeMlXeOnW9mwixD1fx+07UiA5EvK7FomIiNqDHRkREZkaOzIiIjK1DrnZg8RYEzt7OMSuib0hvvS2DyDedyIe4r2/OxviHu9sh9hXV9eWVlIo+cmRLx/AP8+7zypqdXd7GrCe8fLmcbj/4zhmSGerMf5f6/gCaywJ//gIYuZdkGnjvKwjh0D85dV43JhxOebEtY4SiHtqk2LEWjGneliw5nbtqM8gHnPpbIiHvm5scjjgGRkREZkaOzIiIjI1dmRERGRqrJF1kMgBOC6s/EG89n3/yH9AfEPsAYjrVCPETxW4IP7n4xdBnPDSZoiVB8cUUehZIvHPzTJyKMT7fo31qKIxCyFOjsAxQjqf7IF47tTAVlQ+5DXmzIuVWRCvL9fqbutL8QXhNSw17ERo46EOX3kWxNZrDkE8b/hLEKdHnoD4zdrBEL9bh/Gfd3wPYs9OfP+/3fAkxJlR0RD/8sJ/QbzS1k90qqnR8Fhn4xkZERGZGjsyIiIyNXZkRERkaqyRBUlkX1wnqewunCdvaeZTEI+0YS3BJzjgwyZYU5uT8DHEhT8ZBrH3y1EQR2zaAXG4z83YFRhqYGdiveLIGBwD1PN6rIu+PQLrIYlWrIkd82F9pOgE5liNF+fv1MVG4Osv7oFzMTojjTW43ASsvb527zkQ9zuGeejb1vIKzt2VnhOfPYA1sV9f/irEl/faB/GTR/Hzfu5trI0PWXoc39CLx5WBlfh8U19sz46rsOaVGYW1eLPgGRkREZkaOzIiIjI1dmRERGRqrJEFiTcN57m7ZwqOvzg3Cv9n8IkP4tv34HiP9Z9hfeX1C3BM0fLhSyH+1eM5EH95L65TZPvoC2Obq6sNj1EAtLkSI/r1hXjvxQkQN03Ez/uJwThxXW8rjuHxCdY73q5Lhzh/3VUQW2u1uRR9WhiLa4kVXIhjGafHHBadQ2vTnOGFEC84bzrECbvwkNKdxjNGphvHWH36cyfExT/+E8RN2ri787fcDnH6TVgzG1y9AWJ91J5ek7MXaXMzpr4L8eSeWBM7oTCn/7B+KsRDm7BmGi54RkZERKbGjoyIiEyNHRkREZkaa2RtZO2JY272X+CAeGyPLyHWr4W7vTg/2cZCHF8y+D845qdk7ACIR8XhGKDf9X0b4ovvHQhxxNsjRZf6fCnEXFvq1PTvW0TEk4ljqMrvboL4mTFPQzzMht9pb6s+7gvrEytr4yEuWPRjiEcs/RxffqIeQqXlnKUnvt8jd+D+zrkZ6zciIoNtdoividkL8SJtbsCIQhxP6anA7bsy9/edhseemf5/rb7m+x9iTazfw/h8wHVsC56b/KDPJxBP73VMewF+vye0OV79rWEXLnhGRkREpsaOjIiITI0dGRERmRo7MiIiMjXe7NFGnjG4KOLVPy2CWJ8U+LbdkyHe8CG+fvjLRyH2RQf21eg3Dqwe8wzE8wdMNLzmk3fwZgXZXhbQe3Yp2uBma0wMxK6bcFJmEZHpP8PvfFbvEoiNN3O0PqmvPgD64xO4OGv1UBxcfPyXZ7S6PwPt39bBo3AhztQW6vpW7QYUuwXz8oYBOED234kTcAcVgTXRTPQbgGKuOWDYJsuON+Dcsx8nLkh+XBsE/3Fpu9oUkZYCcWxE63/TEdrNIYYR1ibBMzIiIjI1dmRERGRq7MiIiMjUWCM7XVYsIBwbhvWOi2JwIUt9UuDiT7GekY7lFVHlWjFhWEZAzdOvdTu09mbYceCqiMhHUWcZHus29JrY2cMhdl2Ak63ek4cLIIqI/DjWjfvwUwMz1CN0CnNmblIpxL+4DGtw7WWzYI5ESvQptvyWR3Di4WUVmRDHH8EBvNq8xV1K0zjMmdVnLjBso//+X+XhZODWTVsDe1Mtb4/NGA/xwNs+hdg4ABp5tZz7qDEK4t7b8f3CVcBnZOvWrZPLLrtM0tLSxGKxyMqVK+F5pZQ89NBD0rdvX+nRo4fk5OTIZ599Fqz2Upg7pg5JqXpfPpA1IiKyevVqeJ75QcfUIflETs7i7nA4eAyhdgu4I6utrZVzzjlH5s+f3+Lzjz32mDz55JOyaNEi2bhxo/Tq1UsmT54s9fX1LW5PXYtXPBIjDhkiZ7f4PPODvOKRXuI45fPMEQpUwJcWp0yZIlOmTGnxOaWUzJs3Tx544AG5/PLLRUTkxRdflJSUFFm5cqVcd9117Wsthb0kS19Jkr7iUU2G55gfJHIyR+JVkuyRTw3PMUeoLYJaIysvLxeXyyU5Od+OlXA4HDJu3DgpLi42dRJaIrCeUDkCB1yMjGrQXwGRtcoGcc99tbi1tiDe8YE4jik2Aiec1enXuut8WMvY24iLPIqIWBtxXJLXsEVwhVN+WM/CMXT7HsHn7xuONTG9HiZiHGPlj/4d6fQaWoR2wSRSOnYCV33C2Ja4vZgzhzdr45Zc7avjhVOO6Cw2rB/tvQgn3O1hwedFjJ9pUxxuE2XHfYhPm+g5Gp/3jMYa253/8xrE+qTOgR7i7yu7GuKUt3F/4bpMalA7Mpfr5GqjKSmY3CkpKc3P6RoaGqSh4dtOoJqrFndZbckPEeZId8IcobYI+e33BQUF4nA4mn/69+/v/0XUrTBHyB/mSPcW1I4sNfXkWkRuN16Gcbvdzc/p8vPzpaqqqvmnoqILz2nTzbUlP0SYI90Jc4TaIqiXFjMyMiQ1NVUKCwtl9OjRInLyFH/jxo1yxx13tPgau90udv06sQko7V+ACK1eoo/RmTAOx5mtjx+C+2vEms2sbBxoNrmnflml9c+s6AQuxPnSxvGGbYbv2dXqPoKtLfkhEpwc0WuQR87DcWJzhmOt4ZKeX0FsFePCmjp9jJVXW9gyQhsDpNe8/NXQAn3/JtV61bPGhxWP9+r7Gbfx4ti4XSf6Qhyv3RWvvO2rtIYyR/zRfzeHtq7pQa9xYdrkCMyb/31mEcSf1Ld+5qjXxi+I/g/E+qd92a7rIe7XqxLiZ5yFEOs50vOP8RB7dgd37GJHCbgjO378uHz++bffYHl5uZSWlkpCQoI4nU6ZPXu2PProozJkyBDJyMiQBx98UNLS0mTatGnBbDeFKY/yyAk5Lp6vy8K7d+9mfhDwKI/USFVzzGMItVfAHdmWLVvkoosuao7nzJkjIiIzZsyQJUuWyP333y+1tbUyc+ZMqayslIkTJ8qaNWskOtr/rAFkftVyVD6Udc3x3LlzZe7cucwPaqbnCI8h1F4Bd2STJk0SpU4917/FYpHf/OY38pvf/KZdDSNzSrAkS45cJR7VJO/KKqmqqpK4uLjm55kflGBJlknq8hbzQ4Q5QoHjXIttZKvBItkhbXxNeiSOG1vQ/y2I69PxWrcuWqux9bC0fv3/mA+vpf/uExy0nvy+8av21Rqv6XcZWj3KMhLXf+t5Pa4dpY+/sVuwtqGvFSYisqkB3+OXn14L8b69OHavXzquOfeHof+AWB+LuFOb9257A9awvqhPhnitG8cYuXbh8/rEf7bj2P5+7xrHkdmqsU3WEzjQPaH8I3wLX0ePRgwh7XdLeO1jiCdfebvhJfq6gOdE4d/xuVH7Wn3LOm0c2rZGzMsZK+6EeMiLVRC/93PMAW//tzHW8tp2DGdPMcvyZCG//Z6IiKg92JEREZGpsSMjIiJTY43sNKkmvFZ9xqtHIL4k5j6Ip1+8AeL33bgemesoFrijorDGVl+L9ZHXL1wI8agorMEVnUiDuO9CvBZvL8FxbCIi3i5cz4jsh5/Hl7/CmuPaES9BbLe0vpbYa8eTDI8VLPwxxOkrcBBu3DGcFNfSG2d8vzsnF+JKXN5K4rVhfkkf1UCs16viq3H+ztiD2lpXvtYrHnqOixhrJF03YwLnq8XPu9/1uw3b/GzwbRAfGovjF2sG4vYW7QMfuAqn2oo4iDWwwQe24P4ux/XhXrn4aYj18a3zjozC9//0K4hZIyMiIuoE7MiIiMjU2JEREZGpsUbWRt7tZRAPeagXxJ88j3MnOrT6RVzdHtyhNhegZxDOaVc6DudkGxWFcy8e9eD6ZbajOB7EV9v6emZdjbdPPMR3n4VzVyZasSamjxNze/Hz+tW/cLyOiMiw57dB7PG3dIj2fOLi/RAnaWve6XP7Ka2myXpVePHVtTAu82MsdCZuw+9Y/851et1SXw/MGhsL8b5LMI8zo3D/+vpozxRfCPHQ2s2ttidc8YyMiIhMjR0ZERGZGjsyIiIyNdbIgkQfUyJaDc0fa0+cQ82dhTW3M+04J1uDNnHzkq+yIU48jONNPO1cJ8rsbJbWf/+tjTgRYf4XuK7T0CWVhtd4/dXE/PG1XgOjLijI33nt90ZAXHDR8la3X1WL83UOWtY1co5nZEREZGrsyIiIyNTYkRERkamxRhYmPGNwvayrf4rjns6Nwv85SnCZKPGs6AOx94A2HoT1l1Z91YRzKX65G9dxGrHns85sDlGLLDacg9V5P87nOaUXjk1sUDiO7KkvLoI48fODEOvj1IwNsBgfa2Wh5c7CMzIiIjI1dmRERGRq7MiIiMjUWCMLEf1a957JOPffrfG4zpBVcJzZ6upzIO6z8RjEPo/fq930HQNthyE+YwDWDpQT574UEZHKKuNjRB0oIi0F4rzUlRDHWHAdwkt3ToO49/9oc7pW7G39DbWaWMSIIYZNvDu1+nEIamY8IyMiIlNjR0ZERKbGjoyIiEyNNbJOYu2FcyfKkAEQpmfjXIoJEXitW19H6KWN4yEeXo7rHnV31kasEX5anwqxLw4/b32c3gtDl0I8acZ9hvfQ16AzzLdJ1E76HKx7r8B1Cc+O0seH4iF9bzHOrZixsySwBmj1LkM9rIVtQoFnZEREZGrsyIiIyNTYkRERkamxRtZZMvDatmtiPMS/7P8fiCMF50hz+3ByxaiD+NWpem3yxW5OlVdAvOaF8yH+0c8/hHg8liSlbwTWJn56yTuG93jnn7jPiA+2a43ANc7EEuD/jVZtDE+yNp9mkiOg3UW4jkDsOeAKrD3U6dSIDIhzf7YSYrsFjwPLjmOODH4Wx4l5mrDWHniDQl8PawnPyIiIyNQC6sgKCgpk7NixEhsbK8nJyTJt2jQpK8OVkOvr6yU3N1cSExMlJiZGpk+fLm63O6iNpvBVrnbJJlUo78lqERG5/vrrmSMEytUuKZG1IiIyaNAgHkeo3QLqyNauXSu5ubmyYcMG+e9//ytNTU1y6aWXSu13bju+55575I033pDly5fL2rVrZf/+/XLllVcGveEUnirlkKTLIBkjF4qIMEfIoFIOSZqcvGS2cuVK5gi1m0Wptl/0PHTokCQnJ8vatWvlwgsvlKqqKunTp48sXbpUrrrqKhER2bVrl4wYMUKKi4tl/PjxfvYoUl1dLQ6HQybJ5RJpsbW1aa3Sx2ZYe8f7fY1n/wF8wM/HZo2OhvjLX50L8fQfvg/xI8lbIa7y1UP8vZLbIE57AN/fty28xpF5VJO8K6vkiy++kEGDBoU8RyIHYI2y6v/wdYWjXsHttRrlMd8Jwz6vLfsxxHs34pid6ENY46pPxO/M08vPn572b2bqcJz/8UbnRohtFhxTVOfDwt+CV34A8YACnM9Ttbd+EoBv8qOqqkoaGhpMeRzpDEduz4b46fynIR4Z1QTxqH/dBfHQWfgdh2uNqyXfzZG4uLhWt21Xjayq6uSkqQkJCSIiUlJSIk1NTZKTk9O8zfDhw8XpdEpxcXGL+2hoaJDq6mr4oa6DOUL+MEeovdrckfl8Ppk9e7ZMmDBBRo4cKSIiLpdLoqKiJD4+HrZNSUkRl6vlO6QKCgrE4XA0//Tv37/F7cic8vPzmSN0SjyOUDC0uSPLzc2Vbdu2ybJly9rVgPz8fKmqqmr+qaio8P8iMo2dO3cyR+iU7r33Xh5HqN3aNI4sLy9PVq9eLevWrZP09PTmx1NTU6WxsVEqKyvhvym32y2pqakt7EnEbreL3W5v8bmgsWK94+h0XMvryPexHiUiEhGJ9YYzCuIhVju/wLfogTWxQ1ecCXHmxVjDmm5Ybwy/iqITaRAnPYV1Pd92HAcVbj6Vj0VE5I033giLHPG6sL50YAfWLOtH4tyMMRbMmd5WXC9OROTfI16DuGoY1pgOefH/xD4ROK6sp/Ye/ti07fU6nq5B4e+0YFQNxNaEeIi9bvyMOsObb74p7733XljkSDiwROJxwHYlfif63IorarEum/y+dkg3UU2sPQI6I1NKSV5enqxYsUKKiookIwMH62VmZorNZpPCwsLmx8rKymTPnj2SnZ2t7466IKWU7FJb5bCcvDlm4MCB8DxzhJRS8I8OjyPUXgGdkeXm5srSpUtl1apVEhsb23y92uFwSI8ePcThcMitt94qc+bMkYSEBImLi5O77rpLsrOzT+tOIzK/MtkqLqmQkZIlpfK+uN1uqaurY45QszLZKm45eekvJiaGxxFqt4A6soULF4qIyKRJk+DxxYsXy8033ywiIk888YRYrVaZPn26NDQ0yOTJk2XBggVBaSyFv73ypYiIlMrJ4QVDhw4VEeYIfeubHBH5Nj9EmCPUdgF1ZKcz5Cw6Olrmz58v8+fPb3OjyLxyLCfH/bQ2BoQ50r3lWK7yO0aIOUKB6BaTBlsisCh+5BzskO879y3Day6PwSlzfvKn6yH+ahveLODrhUXYRy98FeIreuGAan2yT70wv/n4Gbi96zjE3m5SxA0aH35ethosD1f58PvrGYHbWwUHN4sYb7ZI1G4I6W31v4+OVKdwsKzP17nvT4GznDkY4tfPehZiuwVv+vrNq9dAnPEyLpzZXY4SnDSYiIhMjR0ZERGZGjsyIiIytW5RI9NF1mGtYE9DomGbJAfWO/TBr03Dsaai62GJ0t8VohMKB8/+9Cuc0PWrZ4dCnFj+UavvR63TJ8TNWH4U4h+eczvEc4YXQnxNDC5QKGKsc+r0mphHMGeaVOs5pPNqFY9tjTgAeO3xERA/88H/gzj9LWyP9xAutEmdTx8AfWhcb4gTIvA71o8b/YtwQd3OnPg5nPCMjIiITI0dGRERmRo7MiIiMrVuUSPTrxs738RFEpdHTTC8pu9lVRD3tDYYtgnEF/XJEBcdwBpY5PNYp0tYheNBfN302ndH8W3HcYL9HhgG8YLzpkO86JpDhn3cPBDXxtIXttS/87VuHCPk2oXPC84pbGDRno/fiTWv3mWY18M/2om7r63T3i+wGh0FgTaBeeV150Gcdy/W4uu18aX3778YYtsmzGM/KdRl8YyMiIhMjR0ZERGZGjsyIiIytW5RI9NZt2DtYOiXvQ3b/OuVicF9z0a81p1YXQuxZx8utKlYv+hY2lyVvm248GnCLvzTiCg0Lui4MmlSq2+hf+fx2ncee3ArvsAX2Mx4yqvliJYz3bVeYiZRx/FbWvAFjv17uzfWZvc+OgRie+3mjmmYyfCMjIiITI0dGRERmRo7MiIiMrVuWSNTDTgmzHPAZdyopcfagRUvc1EerG95KoxzLUpLj30Hv3My0OqYPVZuwvifOM7ssBXHCto9rIm1hGdkRERkauzIiIjI1NiRERGRqXXLGhkRUVjSamiKgwFPC8/IiIjI1NiRERGRqYXdpUX19dRBHmkSCWzGHgojHmkSkW+/z2BijphfR+bHd/fLHDGvQHIk7DqympoaERFZL/8OcUsoGGpqasThcAR9nyLMka6gI/Ljm/2KMEe6gtPJEYvqqH+J2sjn88n+/ftFKSVOp1MqKiokLi4u1M0yperqaunfv39IPkOllNTU1EhaWppYrcG9gs0cCZ5Q5UhH5ocIcySYzJAjYXdGZrVaJT09Xaqrq0VEJC4ujgnYTqH6DDviP20R5khHCMVn2FH5IcIc6QjhnCO82YOIiEyNHRkREZla2HZkdrtdHn74YbHb7aFuiml19c+wq/9+naGrf4Zd/ffrDGb4DMPuZg8iIqJAhO0ZGRER0elgR0ZERKbGjoyIiEwtbDuy+fPny8CBAyU6OlrGjRsnmzZt8v+ibqqgoEDGjh0rsbGxkpycLNOmTZOysjLYpr6+XnJzcyUxMVFiYmJk+vTp4na7Q9Ti4GCOnB7mB/PDH9PniApDy5YtU1FRUer5559X27dvV7fffruKj49Xbrc71E0LS5MnT1aLFy9W27ZtU6WlpWrq1KnK6XSq48ePN28za9Ys1b9/f1VYWKi2bNmixo8fr84///wQtrp9mCOnj/nB/PDH7DkSlh1ZVlaWys3NbY69Xq9KS0tTBQUFIWyVeRw8eFCJiFq7dq1SSqnKykpls9nU8uXLm7fZuXOnEhFVXFwcqma2C3Ok7Zgf5I/ZciTsLi02NjZKSUmJ5OTkND9mtVolJydHiouLQ9gy86iqqhIRkYSEBBERKSkpkaamJvhMhw8fLk6n05SfKXOkfZgf5I/ZciTsOrLDhw+L1+uVlJQUeDwlJUVcLleIWmUePp9PZs+eLRMmTJCRI0eKiIjL5ZKoqCiJj4+Hbc36mTJH2o75Yb7fp7OZMUfCbtJgap/c3FzZtm2brF+/PtRNoTDE/CB/zJgjYXdGlpSUJBEREYa7Ydxut6SmpoaoVeaQl5cnq1evlnfeeUfS09ObH09NTZXGxkaprKyE7c36mTJH2ob5Yc7fpzOZNUfCriOLioqSzMxMKSwsbH7M5/NJYWGhZGdnh7Bl4UspJXl5ebJixQopKiqSjIwMeD4zM1NsNht8pmVlZbJnzx5TfqbMkcAwP5gf/pg+R0J8s0mLli1bpux2u1qyZInasWOHmjlzpoqPj1culyvUTQtLd9xxh3I4HOrdd99VBw4caP6pq6tr3mbWrFnK6XSqoqIitWXLFpWdna2ys7ND2Or2YY6cPuYH88Mfs+dIWHZkSin11FNPKafTqaKiolRWVpbasGFDqJsUtkSkxZ/Fixc3b3PixAl15513qt69e6uePXuqK664Qh04cCB0jQ4C5sjpYX4wP/wxe450WEf29NNPqwEDBii73a6ysrLUxo0bO+qtyKSYI9Qa5gedrg5ZxuWVV16Rm266SRYtWiTjxo2TefPmyfLly6WsrEySk5Nbfa3P55P9+/dLbGysWCyWYDeNOolSSmpqaiQtLU2sVmMpljnSvXVkfogwR7oCfzmibxx07RlVX1FRccrTXP6Y76eiooI5wp9OzQ/mSNf6OVWOfFfQx5F9M6o+Pz+/+bHWRtU3NDRIQ0NDc6y+PkGcKFMlUmzBbh51Eo80yXr5t8TGxhqeY45QMPNDhDnSFbWWI7qgd2StjarftWuXYfuCggJ55JFHWmiYTSItTEDTOnkcafGyDnOEgpkfIsyRLqmVHNGFfBxZfn6+VFVVNf9UVFSEuknBYY2AH4stql0/3VmXzRGdljOGHzqlbpMj1KKgn5EFOqrebreL3W4PdjMojDFHqDVtmZmDOdK9Bf2MjKPqyR/mCLWG+UGB6pBJg+fMmSMzZsyQ8847T7KysmTevHlSW1srt9xyS0e8HZkQc4Raw/ygQHRIR3bttdfKoUOH5KGHHhKXyyWjR4+WNWvWGIq3ZmaJxI/OcuZgiA+N7Q1x5QgFsb+V4GzHscCZ8Y9juMEXWAPw1da2vsMw0x1yROcvZw5nYs7okov2QuzZ3XXrQOGYH/r3p3z4Ny0+bye2hr6rw5ZxycvLk7y8vI7aPXUBzBFqDfODTlfI71okIiJqD3ZkRERkalwhWkSkhQF3kf3SIG4chPO7HRsaDfH5P9sC8eQeh4LUuJMOXhYH8atF50M85IVKiNWOzzH2eILaHhLD2K7I/pgz7kvSIbZNPwjx62c9C3FCBN4+3qSw5nLbbVMhrrnBCbHq1QPjPfsxrm/AuKlR6NQizhoGcflViRDHVGCNLLkQa5giIp492mPBn9o2qKw9e0Js6YfDHdQ+l+E1vrq6Dm3T6eAZGRERmRo7MiIiMjV2ZEREZGrdskZm0aay8Wadadjm8zytPnHWOoj3NeCYn1Wbx0CcuBnrJ0kf1eAbeFu/Vt6UgDW4G+e/AfGbV/0J4ltH/QTiupfGYnuWf2R4j3C4tm1mtVeeB7Hnp0cg/svw+RCfG4V1Sp/251ev8PmtDb0g3vIB1mysBfj9XTEcv+NXN2MO9KjAyXP7/24jxN19HJQ+TqxiCtbEXrj5LxDXK/w8Z03Fv0ERkQG/jYHY97E26XGIa2b673zk6nMgdt72GcRfLBtt2Efq4lKIQ3Fc4RkZERGZGjsyIiIyNXZkRERkat2yRnboZqxn9bu+3LBN9IozIC76fRbE3p64Rlj0ZPwokzdgvcS7vSygNupfzPLJ4yB++tLpEA+9Ga+9z3p4JcS3nDPL8B6D79uMD3TzGklrItP7GR+bicuMrDlzGcQ9LJgjR3xNEI9bMxviiCqsq/begeMbh717AOLLVuP3d6tjD8QPTt0A8Uat5vbnJVMg9lQYx0F1J/pYy/Q1RyG+beJNEBdl4jjAwqxFhn1+70H8u8u4F8cWdvZ8mf7uD+j1Exx7+FwG1uZ/dv0PDPusfktbWuezL9vRwrbhGRkREZkaOzIiIjI1dmRERGRq3aNGps2laNWmmKvPN65xlFZaiq/pg2NKdj/ogHjV2D9C/CPLLyAe+CjWSwKd506/lt7nbziX49Y0rPs13YTj3v56+TOGff75Lzh3X1de3ypQFht+X+W3DDBss24Efuc9LDjXYUkj1hxvLvkZxCN+8SnEvtoTECsvvt4bgTU0mwWftwrmuV6jO89+HPeXhDks3bxGpvNpde0+T+Hf2JsLcK7L62KM86s+M+ZFiO+8ApelSfsr1tKDPgZLO/bpNbEzHsfa+u/6vg1xnbbm2uaNQw1vMXT/J+1pYVDwjIyIiEyNHRkREZkaOzIiIjK17lEj0+YzS/wbjr9pca2u2FgI917RH+JnxjwNcZpWv2iK9QXayoD46ushPuO53RDPrsN6zPw7Fhj2of9OHX693kQiUnH9ud4TjOsw9bZiTWxzA+ZZXsHPIXYuKYHYG+h6YFqO+d3cgv+nRijjunvUCu24EV2GOfDox1hjvmS8cRxZlh3nTL36p0UQry3Jhti6vrTVNvil3w9w9nCIXfficeNlrSam5/QfjoyA+IzX8fUiIr7a2sDa2AF4RkZERKbGjoyIiEyNHRkREZkaOzIiIjK17nGzh0a/uUNfXE5E5Mj0kRDfO+tViM+0YdHzhWpc9NB+tHP/R/Ds3Qdx+pt4s8pbN4wyvMZQeN4yHmJD4bkb0QcL3+h81+9rtjfgxMJJW3Ex1UAHwRtYA7tZw6vwhiOvhHYRR7Pz7MMJdQf+DnPkmsduMLzm32ficWNWb7zhZ/m950KcVo03Z/hdiNPPzR37HsHN3xyDEyP0tvaE+IAXb/B6/r8XQTxkq3Hwc8fe1nZ6eEZGRESmxo6MiIhMjR0ZERGZWreskVl74nVh109HG7b55V0vQ3xxT5xQdcJGHHA84CefQ9y/cSPEqpMXrVQ7sD1r5k80bLPmoT9BvGTaJIgHb2zfRMddiT5Bb0tiI3DS3yYHLmIYqdUzAh3sahmWAfGo6PXaFq0PmN7ZiN9nxOEqiFuYFoC+S/u+1Dac9Llu6VjDS179H1xI84ZYXBx1jVazuviBOyA+4540iPVaeKQT91/+IOZA4RgcpJ0cgce+g1pNbOqHt0M8ZHElxOEw+LklPCMjIiJTC7gjW7dunVx22WWSlpYmFotFVq5cCc8rpeShhx6Svn37So8ePSQnJ0c+++yzYLWXwtwxdUhK1fvygawREZHVq1fD88wPOqYOySeyQUREHA4HjyHUbgF3ZLW1tXLOOefI/PnzW3z+sccekyeffFIWLVokGzdulF69esnkyZOlvt44Rxd1PV7xSIw4ZIic3eLzzA/yikd6ieOUzzNHKFAB18imTJkiU6ZMafE5pZTMmzdPHnjgAbn88stFROTFF1+UlJQUWblypVx33XXta22QeDJxzNf0mUWGbX7YC69lP34Er3/3+4sNYn0S31DTx8rpY5pERJr0a/5BuNCcZOkrSdJXPKrJ2CaT5IeIsX70/O7zDdvcPOofEF/R6yjEvgWvQ/yrf18L8ZCXcKHLpjisqe29GGtamRfhmKLMqMAmES6tx4Ugva6DAb0+WJIsfSVeJcke+dTwnJlyRP8bS1z+sWGbJ+KvgnjIz3Gy8fF2rFk9fDZewZg/9hqIY3viJMR7LsdFgfXJzP3VxCZrNbF+D0NoWFw0XAW1RlZeXi4ul0tycnKaH3M4HDJu3DgpLi4O5luRCTE/yB/mCLVFUO9adLlOLnOQkoL/JaSkpDQ/p2toaJCGhobmuLq6OphNojDSlvwQYY50J8wRaouQ37VYUFAgDoej+ad///7+X0TdCnOE/GGOdG9BPSNLTU0VERG32y19+/Ztftztdsvo0aNbfE1+fr7MmTOnOa6urg56EhrGjWmLy90av8Xwmpm7L4O47AWcw6zPCaw5RfRNhdhz4NT/PXYKbcySPqZJRCRCH9fUwdqSHyKdkyM678FDELu3n2vYxjMKx5ZFauO4ro7BhUovvupxiN/4/iCI9XFoF0TjmKGECP07xPfTF9Js0OqUf9szDuIYLy7GGg7MlCO6lsZYpa+ogPj2iTdBvG7c/0E8pRfO57j/t/+F+INjZ0C8qN9yiLPsWPc+4sNjnd+amL+5HcNUUM/IMjIyJDU1VQoLC5sfq66ulo0bN0p2dnaLr7Hb7RIXFwc/1DW1JT9EmCPdCXOE2iLgM7Ljx4/L559/O2tEeXm5lJaWSkJCgjidTpk9e7Y8+uijMmTIEMnIyJAHH3xQ0tLSZNq0acFsN4Upj/LICTkunq/nidi9ezfzg4BHeaRGvr0rlMcQaq+AO7ItW7bIRRd9O7X/N6fzM2bMkCVLlsj9998vtbW1MnPmTKmsrJSJEyfKmjVrJDo6+lS7pC6kWo7Kh7KuOZ47d67MnTuX+UHN9BzhMYTay6JUeF0Era6uFofDIZPkcom02Py/4DREnIXjxhb95zmIW3qXSS/+AuKMVTjmp+fjWAP75IPBEA/+LY4p6ew5yiLTcW2s8nm9Ddu8P+6vEI99ZQ7Eg/M/hDiQuRY9qknelVVSVVUV9Ms8HZEjBlasP534UaZhE++swxA/NhTHlZ0bheOM7JbA/m/0CNbgmhTGPSw4zkzXoPD9z1pzJ8RDbzPWhjtLR+aHSCflyOnQ6tC+iaMhvmj+BxD/MnFnq7vzaWvKWQX3r3/nU3fgOLQe9+P9Ar6PtPcLo+4gkBwJ+V2LRERE7cGOjIiITI0dGRERmVq3WI+sMbkXxPoV81+7LjG8xvkmjr84MioG4gfT34R4/gV4bboyDWcmkM++PI2Wtp0+Vq56LK5T9NCoVw2vWVU7EOLEj/F6u/J27hpqYUVbP67HP0sMm0RuxbWi7r4kF5+/Esei3TXoHYgH2XCuw48bcNzTC7vHQ3zg0z4Qv37ZkxCPisLM1mtyP87cBPGHNrx5ojuvN9dhtJpTZCmuE/jMhgsh/vnUjyCOseJ3pM+u6VU+iFfU9oW4binG0ds2t9o+s+IZGRERmRo7MiIiMjV2ZEREZGpdskZmjY2F+NPr8Mryv2txzNdXeRiLiFg3l0LsiMS59r5qwnrFttdGQJxWjvWI9tJrYPqaavr8kW+MwXn9vC1cCp/5k7sgjl+/ATfoItfPg8JnrBd6duM8eonPYizPY979vdeZEFsdWAPzHsJxaTFNOBfi0Ii9EJdcMgDiUVE4T59uUDTW5D4U5ym2pI6iGrEOaTkR2JpyOn2s4ZK9uG5e4tZKiH3aGmpdBc/IiIjI1NiRERGRqbEjIyIiU+uSNTKLE8f33DBuwym2/Hr7Jp/hMX0KysjKBojrfThmp2YYrv1k6dED91eD65f5o9fE9s8cDfHVPy2CWF9T7UsPvv7G1XcY3mNYyScQ+1gTCy6trubTckCP/YrAesoX9cn4fFzrNTIKAW2uRcsIXIMu4yz8zmyW9tXMrNpcjPr7G+Iu8jfPMzIiIjI1dmRERGRq7MiIiMjUumSNzBeFv1aG/dAptgwevQ5XknEWbvBJGYSWSKyxRWhzM+69AufdW/DzpyE+04bjxu7Y8yOIP3prOMQjlmhjnETEU1dneIzClz4X4subx0E8dyqOXfS3XplYLa0/T4HR608iYj0b/w73/RprUm8PexniSMHaeoPC2rsuUpt98W9DX4E459e3QdzvYWyP7+NduEOT1sx4RkZERKbGjoyIiEyNHRkREZlal6yR6ZoUXkdOiDwOcWMirvkjIhIVqX00frr8Hzk+hHjV9y+AOLnPGIj3TsL6RdJYN8QLhmJNTDflk5sgjnw+EeKBq7E9nnqsqZH5WY8HNuZoai9cC+sfwyZBrPR6CbVOq4np9TARkX2PYPzmmGcgTrTieM8jvhMQ3/jpta02Qa+JJVqxxqa/3/cenAVxxr24bqE+f6hZ8IyMiIhMjR0ZERGZGjsyIiIytS5ZI4s4XAXxkq+yIV496gWIF/4S14ESETmcMRbiqBocXxEbgdeyz43C/wmeu+MvEH/VlATxBdH7IO5pxXrH6lq8dv3EH6+BOOW/uDaVpwLnWvS1sH4WdW8JEXaID43tDXHithZqbsyjU4ocgGM9yx80fn6FYxZBnByBNbGSRvx8by75GcQDHjXOA/td+jgxvSamv98zY16EeNY1eRA7X8b38+zF41S44hkZERGZGjsyIiIyNXZkRERkal2yRuapwPpR3O9GQ/zKMzjeo2DQ64Z9DHsI1x+zWbDPN85jh2NKsuw4l2KiFa81f28TjufouSYWYr0Glri7GGKPocXU3Vi08olXX4tKo8/LVzkCt0+KMNZ4FGtkzSLT+0G86+e47uHLmU8ZXqPXqE4onC/z2newRnXmb3FeWM9Xe1ptkz534uRHbodYr5ll2XGc2fw7FkB8S188Lg1/EnOixXFmYTA/I8/IiIjI1NiRERGRqQXUkRUUFMjYsWMlNjZWkpOTZdq0aVJWhsuT1NfXS25uriQmJkpMTIxMnz5d3G73KfZIXU252iWbVKG8J6tFROT6669njhAoV7ukRNaKiMigQYN4HKF2C6hGtnbtWsnNzZWxY8eKx+ORuXPnyqWXXio7duyQXr16iYjIPffcI//6179k+fLl4nA4JC8vT6688kp5//33O+QXOB3WLTshfuPGCyFePPqHhtccycIqlL7emL7GmT6u7OIe+yFOsGo1NjteK++zBce+mXXOs0o5JOkySHpJrGyWd6SpqckUOWJG8TuxLruzEeu2Y3HYmIEK0fWYSjkkaZIhZbJVVq5cKb///e/DMkesX7flG3uvGgDx4mlYX8qMMtYYjyustT919FyIk9/FWrpnN9bG/dWf9PXEAq2ZTbBjDe/lK7DO95O+OE5tSL6xDf7qeJ0hoI5szZo1EC9ZskSSk5OlpKRELrzwQqmqqpLnnntOli5dKhdffLGIiCxevFhGjBghGzZskPHjxwev5RSWzrWcnCzZ8/WCgAsXLpRBgwYxR6jZuZYLxKOapEy2yqhRo3gcoXZr1/9kVVUnzyISEhJERKSkpESampokJyeneZvhw4eL0+mU4uLiFvfR0NAg1dXV8ENdB3OE/GGOUHu1uSPz+Xwye/ZsmTBhgowcOVJERFwul0RFRUl8fDxsm5KSIi6Xq8X9FBQUiMPhaP7p379/i9uROeXn5zNH6JR4HKFgaPM4stzcXNm2bZusX7++XQ3Iz8+XOXPmNMfV1dVBT0LVgNeppWQ7hIlbjde2+7yK144/dJ4J8ZYo/OiaEnBNs9/dVQfxGu3a9Kpznod40o33QTzkM7w+76utNbTRDHbu3NnuukZn5IgZJX2IZx3bG3Cc01g71mkN9H9jrZYWN+tI9957b/gcR7T5To9OPxvie2b9A+JsO46xa2lWRL0m9nY+rlOY8M5HuI9Ax+1pNbT21swyo/C49/fxz0L845/fZWjC8D9jm0MxP2ObOrK8vDxZvXq1rFu3TtLTv53cNjU1VRobG6WyshL+m3K73ZKamtrivux2u9jtfqrSZDqfysciIvLGG28wR+iU3nzzTXnvvfeYI9QuAV1aVEpJXl6erFixQoqKiiQjIwOez8zMFJvNJoWFhc2PlZWVyZ49eyQ7O1vfHXVBSinZpbbKYTkgIiIDBw6E55kjpJSCf3R4HKH2CuiMLDc3V5YuXSqrVq2S2NjY5uvVDodDevToIQ6HQ2699VaZM2eOJCQkSFxcnNx1112SnZ3NO426iTLZKi6pkJGSJaXyvrjdbqmrq2OOULMy2SpuOTm8JCYmhscRareAOrKFCxeKiMikSZPg8cWLF8vNN98sIiJPPPGEWK1WmT59ujQ0NMjkyZNlwYIFQt3DXvlSRERK5WRdbOjQoSLCHKFvfZMjIt/mhwhzhNrOolQYzPj4HdXV1eJwOGSSXC6RFpv/F4QLCxbKrWdjkXX/I7j5fzOxiPrssTEQv5N7Pu7vva3tbGDn8qgmeVdWSVVVlcTFxQV136bNkSCznHsWxFcvLYT45rjWb/a48JOrII6/vdGwjT4Bd7B0ZH6ItC1HIuIdEO/8w1CIP/kBDha2a/t9uSbFsM8nnsIFcVMXl0Lsq8ObwoLOz3Fpn3Zcels7LiVacZLh9+qN5z73FeBioElLNkOsPG2b4jyQHOFci0REZGrsyIiIyNTYkRERkal1yYU1Q0IfmPgRTlScfjcOzvzRwhkQ/2fUi7j9M0cgfvnaS3D/2sDHcFjcjszlRudGiFcmTTJu1EE1snBg7YmDfw/cgDXHRye9ArHNggOm9ZrYE09jPUxEJPXFTyDu8JqYzt+A6V+PgPiax26A+N9nvgpxlt1Y74q9FmuxjV+dA3H0gePYhs+/wibqE1a0Ac/IiIjI1NiRERGRqbEjIyIiU2ONrJN4KvA6cuTz50F8xczrIV487O8QP/o/uGjikPv64v73+Zkglrq8Oh/ONXhCGceFfdcX9ckQWxuN9Y8Ap7A1FUs/nLfR/oODENd4cSLwhw6OhfitZ3Gsp14PExHx1dS0p4nBp9XM1LZPIa57CX/Hh+8eB/HwHgcMu5zadxvE7z84GOLt+/BYNeShNIi9n5e30uDTwzMyIiIyNXZkRERkauzIiIjI1Fgj6yzagnkxK0sgtnyK15WnTL8fYps+1MLnDlrTyJwiXDjWcOHLP4B4XsKUVl+fVIrz8CWUf3SKLbsm3x5cADLhFwMhXhk1CWK9hphaXor76+wxYkGgz4OYuBxzYPsWbb7JKFxg+HQMacDPxVcR/Ho+z8iIiMjU2JEREZGpsSMjIiJTY40sRPRr00qbA23gThw3pvM0tT5GiLo+zwEXxM7/PYwbWFr/P1V5sW7r83XlUWNG+hx/3u1lrW7fHT4dQ53Pz2dyOjrjc+MZGRERmRo7MiIiMjV2ZEREZGqskYUpxRoYBUivuxJ1FzwjIyIiU2NHRkREphZ2lxbV18sMeKRJRPnZmMKWR5pE5NvvM5iYI+bXkfnx3f0yR8wrkBwJu46s5uv1e9bLv0PcEgqGmpoacTgcQd+nCHOkK+iI/PhmvyLMka7gdHLEojrqX6I28vl8sn//flFKidPplIqKComLiwt1s0ypurpa+vfvH5LPUCklNTU1kpaWJlZrcK9gM0eCJ1Q50pH5IcIcCSYz5EjYnZFZrVZJT0+X6upqERGJi4tjArZTqD7DjvhPW4Q50hFC8Rl2VH6IMEc6QjjnCG/2ICIiU2NHRkREpha2HZndbpeHH35Y7HZ7qJtiWl39M+zqv19n6OqfYVf//TqDGT7DsLvZg4iIKBBhe0ZGRER0OtiRERGRqbEjIyIiU2NHRkREpha2Hdn8+fNl4MCBEh0dLePGjZNNmzaFuklhq6CgQMaOHSuxsbGSnJws06ZNk7IyXKK8vr5ecnNzJTExUWJiYmT69OnidrtD1OLgYI6cHuYH88Mf0+eICkPLli1TUVFR6vnnn1fbt29Xt99+u4qPj1dutzvUTQtLkydPVosXL1bbtm1TpaWlaurUqcrpdKrjx483bzNr1izVv39/VVhYqLZs2aLGjx+vzj///BC2un2YI6eP+cH88MfsORKWHVlWVpbKzc1tjr1er0pLS1MFBQUhbJV5HDx4UImIWrt2rVJKqcrKSmWz2dTy5cubt9m5c6cSEVVcXByqZrYLc6TtmB/kj9lyJOwuLTY2NkpJSYnk5OQ0P2a1WiUnJ0eKi4tD2DLzqKqqEhGRhIQEEREpKSmRpqYm+EyHDx8uTqfTlJ8pc6R9mB/kj9lyJOw6ssOHD4vX65WUlBR4PCUlRVwuV4haZR4+n09mz54tEyZMkJEjR4qIiMvlkqioKImPj4dtzfqZMkfajvlhvt+ns5kxR8Ju9ntqn9zcXNm2bZusX78+1E2hMMT8IH/MmCNhd0aWlJQkERERhrth3G63pKamhqhV5pCXlyerV6+Wd955R9LT05sfT01NlcbGRqmsrITtzfqZMkfahvlhzt+nM5k1R8KuI4uKipLMzEwpLCxsfszn80lhYaFkZ2eHsGXhSykleXl5smLFCikqKpKMjAx4PjMzU2w2G3ymZWVlsmfPHlN+psyRwDA/mB/+mD5HQnyzSYuWLVum7Ha7WrJkidqxY4eaOXOmio+PVy6XK9RNC0t33HGHcjgc6t1331UHDhxo/qmrq2veZtasWcrpdKqioiK1ZcsWlZ2drbKzs0PY6vZhjpw+5gfzwx+z50hYdmRKKfXUU08pp9OpoqKiVFZWltqwYUOomxS2RKTFn8WLFzdvc+LECXXnnXeq3r17q549e6orrrhCHThwIHSNDgLmyOlhfjA//DF7jnRYR/b000+rAQMGKLvdrrKystTGjRs76q3IpJgj1BrmB52uDlmP7JVXXpGbbrpJFi1aJOPGjZN58+bJ8uXLpaysTJKTk1t9rc/nk/3790tsbKxYLJZgN406iVJKampqJC0tTaxWYymWOdK9dWR+iDBHugJ/OaJvHHTtGVVfUVFxytNc/pjvp6KigjnCn07ND+ZI1/o5VY58V9DHkX0zqj4/P7/5sdZG1Tc0NEhDQ0NzrL4+QZwoUyVSbMFuHnUSjzTJevm3xMbGGp5jjlAw80OEOdIVtZYjuqB3ZK2Nqt+1a5dh+4KCAnnkkUdaaJhNIi1MQNM6eRxp8bIOc4SCmR8izJEuqZUc0YV8HFl+fr5UVVU1/1RUVIS6SRRmmCPkD3MkSKwR+GMSQT8jC3RUvd1uF7vdHuxmUBhjjlBr2jIzB3Okewv6GRlH1ZM/zBFqDfODAtUhkwbPmTNHZsyYIeedd55kZWXJvHnzpLa2Vm655ZaOeDsyIeYItYb5QYHokI7s2muvlUOHDslDDz0kLpdLRo8eLWvWrDEUb8NGC9eCLTb8aCKS+0DsTXJ0aJMiDlVC7Nm7r0Pfr7OZLke6AYstKuDXqKbGDmgJ86OjWHv2hNh77lCI6/tgDvT4ZwnuwOftkHa1V4ct45KXlyd5eXkdtXvqApgj1BrmB52ukN+1SERE1B7syIiIyNS65QrRkQP6Q+zOSTdsc+wsBXHqmQchvtH5LsQ2S+vXjpsU1uGsFty/T+Ggv79svxjigTOO4fZ1da2+H5FOr494xmB9pOLSHobXNMVgntpq8H/fM149ArF3e1l7mhjWLJF4uFQeT+c3QqvnWyK0OBqHIBy6diTEMdccgPjvw5+GOGfDHRCfUZwIsdeNx8FwwTMyIiIyNXZkRERkauzIiIjI1LpmjUybZNJ61jCIj/6xCeK/DJtv2MXIqAaIIwT36RWsHbxZh1PnHPXEQPzW4TMhHuXYD/GIaIwXjnkJ4sf6TcMGfvaloc1E36XXxPbPHA3xZTe/B/H83hsM+0jQ/tWt8mHe/0Duh3jgozgOqaPGmXWGCO24UTEV60XOV3E+R6+rhfqR9nnp9JqWxZmGL++BEx4fPgdngq8cgfv3xmGt/u85eGw7NwrrehEWfP+Y/+Jxy3dkZ0vNDjs8IyMiIlNjR0ZERKbGjoyIiEyta9TI9JrY2cMh3qett7dh1MsQH1dYMxMRWV3rhHhB+f+D2LUjGeKBq3EftmP12KYaHPe1KXoUxO/3GQex+7xoiNP3lRraSCajLxCoWq+fBMqqraTruglz7Le5SyB+4qtLIF667nzDPsdnfgrxk87VEDfF+gJtZtjS55r88hqsiS276QmIc7/3Y4hdu8417tTPx+OLwZrWj8duhHhQNNbdzrLjnKsjorAGqdfye1j0+TPxkH/Qi8elPhu18aqhGCvXBjwjIyIiU2NHRkREpsaOjIiITM2cNbIAa2JvZz4L8eo6HKuR/y+81i0ikvFPvPYc/zleq449uBVi1YDjzvTqh79VfPQV0fq9h1+NWa5V07esvXpBXHvJWRDHlGE9wrvzs8D2r9fEZmBN7O68f0C8tW4gxJGPJkA8bMs2w3tsm3UOxB/duQ5i23Gt7teFeHphgSvDhvG6Ufj5Cn78QRFh0c819COFcX7M7/IqbLNPOzLNOzIRYrXTnONTeUZGRESmxo6MiIhMjR0ZERGZmjlqZNoaPJU/yYL4jrmvQXxDLK65c0wby/Gn318P8ZC/bza8pb7WUGdXqEKy1hG1iz63oetmrC/9aOZaiF9/Cccm9vusHGI9B/zVxPJyX4d4oO0wxAv+dzrEiZs/glhfb0tEpC4VayrPuLDNzjdPYJtNPLei8mIlO/FjrP/NuyQT4tmJJRDrY7haYhzX1brjPhyParPgsTDSUDNDDQpz6NXjuPbiW8/i2MHkpg8Cal+44BkZERGZGjsyIiIyNXZkRERkauzIiIjI1Exxs4clAguaR87GAvQVMbshrvLh3R2XlNwGcdryjyHmYGMKBktGf4gvvQ0L51fEfQjxyga8cUKnD6j2d3NH4dEREP/pv1dCPOBlvDlBv7nhyDV4c4qIyHWXrId4xasXQOwsxRtGTD2FsA8/j/gXiyHe8FpviK8diseVljT1xsm/d0/FhTKVdiqhDzBP/hDbNPCXuyB+zvkOxFbthpORK+6CeMTjeCNc8m78Hc2KZ2RERGRq7MiIiMjU2JEREZGpmaJGptOvK+sDEYsbcDLU2L/FQeyrre2QdlH35uuB9Y+h0S6IP27oB3H0UW1qab0WfPXZEOuTAOu14d9tngqxcyMu9urJxkmLfZH4d9Prhv2iy4ndDvGbLpxk1ncCB+x2ZYbjxtbtLW/4HfoBdvB7rQ+IttjwFZ8+ijnwp9RCiK3agGh9APSA1dp05fU4ubk+iF81Ys6YZYA7z8iIiMjUAu7I1q1bJ5dddpmkpaWJxWKRlStXwvNKKXnooYekb9++0qNHD8nJyZHPPgtseQoyr2PqkJSq9+UDWSMiIqtXr4bnmR90TB2ST2SDiIg4HA4eQ6jdAu7Iamtr5ZxzzpH58+e3+Pxjjz0mTz75pCxatEg2btwovXr1ksmTJ0t9ffe5BNGdecUjMeKQIXJ2i88zP8grHukljlM+zxyhQAVcI5syZYpMmTKlxeeUUjJv3jx54IEH5PLLLxcRkRdffFFSUlJk5cqVct1117WvtV+zaINVvNpicWPsRyHePwm3H/YfvC7sq6sLSrtIJMnSV5Kkr3hUk+G5zsqPUDl8Lk7qGx+BeXX/apysethbX0DclHUmxHrN6pqYvRDbLXaIX79gIcSfjk+G2KcVl63aH1KmfZ/o/lF9LsTRlfgaazS24XT+lpIsfSVeJcke+dTwXFfPEb3mZLHj5+fJHAbx4mmLIM6Man2S4Aht0eHdN+D3FX17H4hPHHFCbHdjl5D+DtbUog4a7y/w7vwcH/D5W0Y4+IJaIysvLxeXyyU5OTnNjzkcDhk3bpwUF3eNgXfUdswP8oc5Qm0R1LsWXa6Td2mlpKTA4ykpKc3P6RoaGqSh4dtev7q6OphNojDSlvwQYY50J8wRaouQ37VYUFAgDoej+ad///7+X0TdCnOE/GGOdG9BPSNLTU0VERG32y19+/Ztftztdsvo0aNbfE1+fr7MmTOnOa6urjYkob8F71b8cADE+sKay374NMS3f3E3xGlFWFMTEZEvKiDs9LFn2mKi+nyT+mcSiuvSgWpLfoicXo6Egj4Gxz7dDfGfv8yBeOiLeJbQNBTHlZ3xOM6j97u+b+P+LT1abc+oKJsWH4PYp9WS6xTWa2bvNda+15YNgfiHc3G+yA2x50Gc8BIuUhvoArFdLUd0+uKlh28cA/Gf8v8P4gn2wGav1Bfa/Ox7zwb0et2Jn2KO1PiM3+eFL/8C4sG/0eay7YRjZ1DPyDIyMiQ1NVUKC78dtFddXS0bN26U7OzsFl9jt9slLi4Ofqhrakt+iDBHuhPmCLVFwGdkx48fl88///YulfLyciktLZWEhARxOp0ye/ZsefTRR2XIkCGSkZEhDz74oKSlpcm0adOC2W4KUx7lkRNyXDxy8j+33bt3Mz8IeJRHaqSqOeYxhNor4I5sy5YtctFFFzXH35zOz5gxQ5YsWSL333+/1NbWysyZM6WyslImTpwoa9askejo6FPtkrqQajkqH8q65nju3Lkyd+5c5gc103OExxBqL4tSSvnfrPNUV1eLw+GQSXK5RFpsLW5jWKfpFlxH6Z68VyG+KgbH42xrwhrbP6vwOrWIyMtFEyAeuBrHRdmOBXlwZgS26fA5OCapcgR+TXqdMOEf2rpQIR4b51FN8q6skqqqqqBf5jmdHOkM1rOHQ3zLP/4D8R/+hOPG+pRgjezAg1j/KMzEekZvK9bEIixYCfCq1usnek3sz0exvc98jPMmqkM4pklEpO97uI9bHl0F8d8qxkPc4z7sbHwfY93vGx2ZHyLhkyO6yP7pEB/5P/y8is5eCrHd0vq5hkewNl7lw5rWJ4342X7ViOPIdJfF4NjGRGvrdVkRkT8cwXXw3sk9H2Lr+lJ8wWl2OYHkSMjvWiQiImoPdmRERGRq7MiIiMjUTLkemT4uIXUx1oeePn41xAuvPQjx62e9APH/JOHYFxGR3KtwOpz3fohjfmq8/q8dByJCm/dueBSOhRsRhde+H70Yr0NvLxmKO9xeFrzGkWH8j4jIoXG9IW5S2jZYxjTUxNaMeQbi3lYcl6bTa2J6DWxrIz7/WuVYiD/8Oc6bOHQHrmemj10UEbH0wjxfvBvz7pnhf4f4yivug3jADvxMAh1X1tV4k3Cy5JsHvguxXhPTv+MVtbjW4l++/B7Erh04v2bKRnz/uC+Ot9q+398wDeLfTF0O8RW98LgkIjKzN44t/PvdmHcZ5WkQe/Ya5/RsL56RERGRqbEjIyIiU2NHRkREpmbKGplOr5n1XoL1Lcvf8de8dditEDekxBj2uef7URBfP3kdxA8k4XxiNgvWFxq09bg+whKX7GjAmlu9D8e63Psp1vm8Pvyf4/AxHGc2rArrgNQ+ek3s6E/GGrbJu/c1iG0WrP8UPfhniCP0opn253dCtT6v3eLKTIif/+9FEA95oRJitfNLiK1NWyHWZ+dsqQ7oPRPHPX2v7yaIpxb9HOIzl+AcpZ5uXhPTRbiOQPz4P38EcflkPHa9VoTj9IYsroQ4dheuBRbjwe9c528E1+ASzNGl87Am+r/XGOev3Hj3PIjvPQvnCF3eB+t4whoZERERYkdGRESmxo6MiIhMrUvUyPzRx654d3wKcXSt8bpv9EGsDZzdA6/9W7V6x/v1OIbnvrLrIG56Hcd3JG2twTf04tXr+MNV+Lw2P1miwrkUPfuN4zsoABb8Pi0jcVxez+uNn+81MXshPqzNc1fehHXPK9+7A9/jMNZhdbbj2Kb+b52AeMjWTyD2t+6Tvn6aDHZCqI+LExGJvQbnKb0iDscMvVLx/yD27sc12Qh5DuAq14N/i8eBT/42DOIhXwX2Hbebdpzx7MbjnhOnsRURkdW34/yN3hCcH/GMjIiITI0dGRERmRo7MiIiMrVuUSPT+SaOhrj87ibDNs+MeRri8+w46mZDA44bu/PJPIjTV+C1Ze8+nM/R35xzHH3TuSL74XxwX/4Kv9+1I14yvMZuwXkI+0Xgn5PLiznT+31c7yv5bzhHqGpq/VtXHsxTn1bPsNiw5maJxvfbf+soiL8/4wOIL43DekxLfrzlNogzlh/FNjVpAyapVYaaV5jPkerdZ6wVv+rGMZY5iTs7qznNeEZGRESmxo6MiIhMjR0ZERGZWreokVl79YJ44OO7IH65L84NJiJis2Af//iR0RC/8jzOH5b211KIPXU4zovCW8OQFIgfOHsVxIlW/+vPNSiscQ2zYY3s6DiscSVtHQRxxFFcK0ppNS6xYd2uqXc0xPsmYY2sIRXb80LOAoi/akyC+La3fyq6xE14iDjjbRw759mDMQXGGo3foaUXjvXzHsEaZKhZzhxseOy+flg//mcVrntnbdTG8Qa/WTwjIyIic2NHRkREpsaOjIiITK1b1Mg85w6B+Ld950PssOJ1ahGRPx45E+K38i+EOO2dUoh9rImZSkRcHMSf/wjrS5f03KO9wlgj02ti2VtmQPz8OS9AvOIizLtN2RkQrzl0FsSjHDgnqDMK17LqZW2AeFw0jl3E2T9F/np0IsRvPYdrTY34+3bReauxbufxdUSFo/vQ13w7Nn00xPWJeG6R8iSO9ets+t9J2c3xhm1GROHYwR9vHgfx8D14T0JH4BkZERGZGjsyIiIyNXZkRERkal2yRqZfh96bg2Mz9DFBpY3GOe6WLcFxYv1YEzM1PScOX4n1qN9MxYWW9BzxCc5rKCLy6nFcsy7+2ViINzyG48R+Eoc1r8G2LyG+OuZziK3aGml1Wn2q6MQA3P/OmyA+vBnHxp2x/BjEqZ+XQuxlTne4iL6pEDdei99J1UHMoVQ7jiVUDVgXDTa9JnbgppEQ/+4HLxteo+el3YV/a6q+Y9sswjMyIiIyOXZkRERkagF1ZAUFBTJ27FiJjY2V5ORkmTZtmpSV4bID9fX1kpubK4mJiRITEyPTp08Xt5vLn3cX5WqXbFKF8p6sFhGR66+/njlCoFztkhJZKyIigwYN4nGE2i2gGtnatWslNzdXxo4dKx6PR+bOnSuXXnqp7NixQ3p9PZ/hPffcI//6179k+fLl4nA4JC8vT6688kp5//33O+QXaInyYT0jZg/GntOZ7cuihVE2fKAe572TLjC+xqJdj7cOwhqM5Vg1xJ4DLsM+KuWQpMsg6SWxslnekaamptDkiFZfsowcCnHP63FdpSt66ess4Z/Ga8eTRPeXp6+COK10N8Tzl14G8Z8T9JFdgbEdx98p/R2sPcR/fhDiWFcJxOGyVlilHJI0yZAy2SorV66U3//+92F5HOkI3iQHxLlDCiG+dsxXEGf/fA7Ezlf1dQ4xb5W2Bp5oc8ZatbkcPaNx7sQL5hdDPKv3HyHu3cKcoxM/xvGTg57T5uPshLwLqCNbs2YNxEuWLJHk5GQpKSmRCy+8UKqqquS5556TpUuXysUXXywiIosXL5YRI0bIhg0bZPz48cFrOYWlcy0XiIiIR52cIHfhwoUyaNAg5gg1O9dygXhUk5TJVhk1ahSPI9Ru7aqRVVVViYhIQkKCiIiUlJRIU1OT5OTkNG8zfPhwcTqdUlxc3OI+GhoapLq6Gn6o62COkD/MEWqvNndkPp9PZs+eLRMmTJCRI0/eoulyuSQqKkri4+Nh25SUFHG5jJehRE7W3RwOR/NP//7929okCkP5+fnMETolHkcoGNo8jiw3N1e2bdsm69evb1cD8vPzZc6cb68DV1dXtz8JtXpV0isfQ/zH2aMg/mWicY65otl4bfjNmU6IF5T/P4gbluOYnT6bcXyIlO+DsMPHVlixnhKR3MewiftS/JyPTMD1shZe+DeI81beAvHgfFwrSbVwLXznzp3trmu0JUcinTjGq/wB/J/t3RG4hpLdgtf+D3hxTNWv/nWn4T2GvbgNYo92FuD8X+3mBEtwbxLWP2/jaMjwd++994bvcaQTNCmstfew4Jyfi+54GuL7Lr4a4ro3syDu5cI6bGMvPA4cycIsuT17HcS/SNwBsVWbY/Sg1zjW0PtKMsb7Nhu26Wht6sjy8vJk9erVsm7dOklP//aAkZqaKo2NjVJZWQn/TbndbklNTW1hTyJ2u13s2k0GZH6fysl/Ht544w3mCJ3Sm2++Ke+99x5zhNoloH8RlVKSl5cnK1askKKiIsnIwNm7MzMzxWazSWHht3filJWVyZ49eyQ7Ozs4LaawppSSXWqrHJaTd1MNHDgQnmeOkFIK/tHhcYTaK6AzstzcXFm6dKmsWrVKYmNjm69XOxwO6dGjhzgcDrn11ltlzpw5kpCQIHFxcXLXXXdJdnY27zTqJspkq7ikQkZKlpTK++J2u6Wuro45Qs3KZKu45eRt5DExMTyOULsF1JEtXLhQREQmTZoEjy9evFhuvvlmERF54oknxGq1yvTp06WhoUEmT54sCxYsCEpjKfztlZPzB5bKybrY0KEnx28xR+gb3+SIyLf5IcIcobazKKWMs6GGUHV1tTgcDpkkl0ukxeb/BW1wMA8XFLw77x+Gba6KwYUV9SKsPqh6awNepV1dPRrilzbhf5LW49qA6mDTLhqnDj9o2OTxocshHhmFN3sc9WFh+NLF90M88NEtEH/35gOPapJ3ZZVUVVVJnDYRaXu1mCNW/DyP3oxF8HkP4KKW47Vyin5zx9QPb4e43wPGPxPfto5fMLCr6sj8EOmc40hbWHvigGTXLaMhnv6zIoj1G9Gs2kwN+mTWTQqPSxHaxACR0vpxR18s9uavpkD81bM4sYCISO8XNuADQepSAskRzrVIRESmxo6MiIhMjR0ZERGZWpdcWNOf1MUfQbywerphm0cm4LXiG8bhdeAfxpVCfK4dByKO7YPv8T9TO3+Q4HfZLP5rcm4v/s4/1OpEGctxAHS4TEIrImKJwN/v2Ah8/kxbPcQbGqIhvnH1vRAP+2sVxL7tODs7UVvoC/KmLi6FeO3H2vACLO3KrN44EbQ+ia/dEtgh/bjCiRl+fwjfX6+JJbyE7y9ycjhFqPGMjIiITI0dGRERmRo7MiIiMrVuWSPz1dZCHP/3TYZtElbgeI+SjLMgXjN2IsT2q3GC2BudGyG2WVpfeDM24gTEo+37If7gBE7j41Xt/x/k+d04nu7wZpz4+IxXcOLjcK4T6QsKJuI80XLH+T+EuGT9MIhHLNAWA9yNCxgSdQS9ZmZdXwrx2lysWS29+zyInxnzIsQjo7DmZdPGjX3ciPEC92SID92Bk20nfoq1/nCqi38Xz8iIiMjU2JEREZGpsSMjIiJT65Y1MgOfsX7lq6nBBz7GefUSt+G15si3+kK8MmlSQE3wxOPkf+6xOM6pX5G2dLu3/WM34g/jWKlYF44RCdfr4S3SvsOE1/DafvUGXMdq8H4sonm0uilRSGhjsqzvbYXYWYyH7N/3/RHE3mQHxDVnxEAcvwlr7979WNtXTbiwplnwjIyIiEyNHRkREZkaOzIiIjI11sjaSqvJeCpwHJLosR/6TIj93sOvRnk8EmzB32P40MfnyGdftrwhkYnoxwF/x52YD3E9Mk8YzIvYEXhGRkREpsaOjIiITI0dGRERmRprZGGqI2piRNTNdNGamI5nZEREZGrsyIiIyNTC7tLiN8tme6RJpHucFXdJHmkSkY5ZBp05Yn4dmR/f3S9zxLwCyZGw68hqvp7jcL38O8QtoWCoqakRh8Phf8MA9ynCHOkKOiI/vtmvCHOkKzidHLGojvqXqI18Pp/s379flFLidDqloqJC4uLiQt0sU6qurpb+/fuH5DNUSklNTY2kpaWJ1RrcK9jMkeAJVY50ZH6IMEeCyQw5EnZnZFarVdLT06W6+uRs73FxcUzAdgrVZ9gR/2mLMEc6Qig+w47KDxHmSEcI5xzhzR5ERGRq7MiIiMjUwrYjs9vt8vDDD4vdbve/MbWoq3+GXf336wxd/TPs6r9fZzDDZxh2N3sQEREFImzPyIiIiE4HOzIiIjI1dmRERGRq7MiIiMjUwrYjmz9/vgwcOFCio6Nl3LhxsmnTplA3KWwVFBTI2LFjJTY2VpKTk2XatGlSVlYG29TX10tubq4kJiZKTEyMTJ8+Xdxud4haHBzMkdPD/GB++GP6HFFhaNmyZSoqKko9//zzavv27er2229X8fHxyu12h7ppYWny5Mlq8eLFatu2baq0tFRNnTpVOZ1Odfz48eZtZs2apfr3768KCwvVli1b1Pjx49X5558fwla3D3Pk9DE/mB/+mD1HwrIjy8rKUrm5uc2x1+tVaWlpqqCgIIStMo+DBw8qEVFr165VSilVWVmpbDabWr58efM2O3fuVCKiiouLQ9XMdmGOtB3zg/wxW46E3aXFxsZGKSkpkZycnObHrFar5OTkSHFxcQhbZh5VVVUiIpKQkCAiIiUlJdLU1ASf6fDhw8XpdJryM2WOtA/zg/wxW46EXUd2+PBh8Xq9kpKSAo+npKSIy+UKUavMw+fzyezZs2XChAkycuRIERFxuVwSFRUl8fHxsK1ZP1PmSNsxP8z3+3Q2M+ZI2M1+T+2Tm5sr27Ztk/Xr14e6KRSGmB/kjxlzJOzOyJKSkiQiIsJwN4zb7ZbU1NQQtcoc8vLyZPXq1fLOO+9Ienp68+OpqanS2NgolZWVsL1ZP1PmSNswP8z5+3Qms+ZI2HVkUVFRkpmZKYWFhc2P+Xw+KSwslOzs7BC2LHwppSQvL09WrFghRUVFkpGRAc9nZmaKzWaDz7SsrEz27Nljys+UORIY5gfzwx/T50iIbzZp0bJly5TdbldLlixRO3bsUDNnzlTx8fHK5XKFumlh6Y477lAOh0O9++676sCBA80/dXV1zdvMmjVLOZ1OVVRUpLZs2aKys7NVdnZ2CFvdPsyR08f8YH74Y/YcCcuOTCmlnnrqKeV0OlVUVJTKyspSGzZsCHWTwpaItPizePHi5m1OnDih7rzzTtW7d2/Vs2dPdcUVV6gDBw6ErtFBwBw5PcwP5oc/Zs8RLuNCRESmFnY1MiIiokCwIyMiIlNjR0ZERKbGjoyIiEyNHRkREZkaOzIiIjI1dmRERGRq7MiIiMjU2JEREZGpsSMjIiJTY0dGRESmxo6MiIhM7f8DnmbbrEzNbJwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(test_images,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_batch(imgs,width,height):\n",
    "    # A function to resize a batch of MNIST images to (32, 32)\n",
    "    # Args:\n",
    "    #   imgs: a numpy array of size [batch_size, 28 X 28].\n",
    "    # Returns:\n",
    "    #   a numpy array of size [batch_size, 32, 32].\n",
    "    imgs = imgs.reshape((-1, 28, 28, 1))\n",
    "    resized_imgs = np.zeros((imgs.shape[0], width, height, 1))\n",
    "    for i in range(imgs.shape[0]):\n",
    "        resized_imgs[i, ..., 0] = transform.resize(imgs[i, ..., 0], (width, height))\n",
    "    return resized_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Generator used because we want the model to load a\n",
    "    batch at a time on the GPU in order to avoid memory problems.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 x_set,\n",
    "                 y_set,\n",
    "                 batch_size,\n",
    "                 resize_info,\n",
    "                 add_dims:bool = False):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.width, self.height = resize_info\n",
    "        self.add_dims = add_dims\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        resized_batch_x = resize_batch(batch_x,\n",
    "                                       self.width,\n",
    "                                       self.height)\n",
    "\n",
    "        if self.add_dims:\n",
    "            resized_batch_x = np.repeat(resized_batch_x,3,-1)\n",
    "\n",
    "        return resized_batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(train_images,\n",
    "                          train_labels,\n",
    "                          32,\n",
    "                          (32,32) ,\n",
    "                          True)\n",
    "test_gen = DataGenerator(test_images,\n",
    "                         test_labels,\n",
    "                         32,\n",
    "                         (32,32),\n",
    "                          True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name:str,\n",
    "              used_opt,\n",
    "              used_loss_fn,\n",
    "              used_metrics,\n",
    "              num_labels,\n",
    "              used_input_shape = (32, 32, 3),\n",
    "              trainable = False,\n",
    "              layers_to_train = None):\n",
    "\n",
    "    if model_name.lower() == \"mobilenet\":\n",
    "        if layers_to_train != None:\n",
    "            pretrained_model = tf.keras.applications.MobileNetV2(alpha=0.75,\n",
    "                                                                input_shape=list(used_input_shape),\n",
    "                                                                include_top=False,\n",
    "                                                                weights='imagenet')\n",
    "            pretrained_model.trainable = trainable \n",
    "\n",
    "            model = tf.keras.Sequential([\n",
    "                pretrained_model,\n",
    "                tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                tf.keras.layers.Dense(1000,activation='relu'),\n",
    "                tf.keras.layers.Dense(num_labels, activation='softmax')\n",
    "            ])\n",
    "        else:\n",
    "            pretrained_model = tf.keras.applications.MobileNetV2(alpha=0.75,\n",
    "                                                                input_shape=list(used_input_shape),\n",
    "                                                                include_top=False,\n",
    "                                                                weights='imagenet')\n",
    "            # Fine-tune from this layer onwards\n",
    "            fine_tune_at = layers_to_train\n",
    "\n",
    "            for layer in pretrained_model.layers[fine_tune_at:]:\n",
    "                layer.trainable =  True\n",
    "\n",
    "            model = tf.keras.Sequential([\n",
    "                pretrained_model,\n",
    "                tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                tf.keras.layers.Dense(1000,activation='relu'),\n",
    "                tf.keras.layers.Dense(num_labels, activation='softmax')\n",
    "            ])\n",
    "            #create mobilenet with more trainable layers \n",
    "\n",
    "\n",
    "    elif model_name.lower() == \"cnn\":\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=used_input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "            tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "            tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "            tf.keras.layers.Dense(num_labels, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(optimizer=used_opt,\n",
    "                  loss=used_loss_fn,\n",
    "                  metrics=used_metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_as_tflite_file(trained_model, out_path:str, save_name = 'model'):\n",
    "    \"\"\"\n",
    "    Method that can be used to save a tensorflow model to a tflite file.\n",
    "\n",
    "    Args:\n",
    "        trained_model (_type_): Model to be saved.\n",
    "        out_path (str): Path to where to save the tflite file.\n",
    "        save_name (str, optional): Name of the saved model. Defaults to 'model'.\n",
    "    \"\"\"\n",
    "\n",
    "    # convert the model\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(trained_model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # save the model \n",
    "    with open(os.path.join(out_path , save_name + '.tflite'), 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. FINE TUNE MOBILENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading dataset = emnist\n",
      "WARNING:root:Please cite the following paper when using or referencing this Extra Keras Dataset:\n",
      "WARNING:root:Cohen, G., Afshar, S., Tapson, J., & van Schaik, A. (2017). EMNIST: an extension of MNIST to handwritten letters. Retrieved from http://arxiv.org/abs/1702.05373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data is of shape: (112800, 28, 28, 1)\n",
      "Train labels is of shape: (112800,)\n",
      "Test data is of shape: (18800, 28, 28, 1)\n",
      "Test labels is of shape: (18800,)\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_0.75_224 (Funct  (None, 1, 1, 1280)       1382064   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_9   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1000)              1281000   \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 47)                47047     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,710,111\n",
      "Trainable params: 2,683,471\n",
      "Non-trainable params: 26,640\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "  91/3525 [..............................] - ETA: 3:00 - loss: 3.1894 - accuracy: 0.2387"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m tensorboard_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(log_dir\u001b[39m=\u001b[39mlog_dir, histogram_freq\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[39m# train \u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_gen,\n\u001b[0;32m     59\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[0;32m     60\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mtest_gen,\n\u001b[0;32m     61\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[lr_schedule_callback, model_checkpoint_callback, tensorboard_callback])\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_images, train_labels, test_images, test_labels = get_emnist_data()\n",
    "\n",
    "# create data generators\n",
    "train_gen = DataGenerator(train_images,\n",
    "                          train_labels,\n",
    "                          32,\n",
    "                          (32,32),\n",
    "                          True)\n",
    "test_gen = DataGenerator(test_images,\n",
    "                         test_labels,\n",
    "                         32,\n",
    "                         (32,32),\n",
    "                          True)\n",
    "\n",
    "# create model\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "metrics=['accuracy',]\n",
    "\n",
    "model = get_model(\"mobilenet\",\n",
    "                  optimizer,\n",
    "                  loss_fn,\n",
    "                  metrics,\n",
    "                  47,\n",
    "                  trainable = True,\n",
    "                  layers_to_train = 70)\n",
    "model.summary()\n",
    "\n",
    "# schedular to decay the learning rate\n",
    "def scheduler_100_epochs(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    elif epoch < 20:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    elif epoch <= 50:\n",
    "        return lr * tf.math.exp(-0.01)\n",
    "    elif epoch <= 90:\n",
    "        return lr * tf.math.exp(-0.01)\n",
    "    else :\n",
    "        return lr\n",
    "\n",
    "lr_schedule_callback = tf.keras.callbacks.LearningRateScheduler(scheduler_100_epochs)\n",
    "\n",
    "# callback for saving the best model\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath= f'Jiani/checkpoints/mobilenet/best_model.h5',\n",
    "                                            monitor='val_accuracy',\n",
    "                                            mode='max',\n",
    "                                            save_best_only=True,\n",
    "                                            verbose = True)\n",
    "\n",
    "# callback to save tensorboard logs for later visualization\n",
    "log_dir = \"Z:/Master I/PML - Practical Machine Learning/Jiani/checkpoints/mobilenet/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# train \n",
    "history = model.fit(train_gen,\n",
    "                    epochs=100,\n",
    "                    validation_data=test_gen,\n",
    "                    callbacks=[lr_schedule_callback, model_checkpoint_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "layers = [1,2,3,4,5]\n",
    "fine_tune_at = 4\n",
    "for layer in layers[fine_tune_at:]:\n",
    "    print(layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load best fine tuned mobilenet model and save in the tflite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_0.75_224 (Funct  (None, 1, 1, 1280)       1382064   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1000)              1281000   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 47)                47047     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,710,111\n",
      "Trainable params: 1,328,047\n",
      "Non-trainable params: 1,382,064\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_0.75_224_input with unsupported characters which will be renamed to mobilenetv2_0_75_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\test\\AppData\\Local\\Temp\\tmp75vm0qg4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\test\\AppData\\Local\\Temp\\tmp75vm0qg4\\assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(f'Jiani/checkpoints/mobilenet/best_model.h5')\n",
    "model.summary()\n",
    "\n",
    "save_name = \"fine_tuned_mobilenet_best_model\"\n",
    "save_model_as_tflite_file(model,f'Jiani/checkpoints/mobilenet/',save_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MY CNN MODEL "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method to train using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cross_fold_save_best_model(model,\n",
    "                                     train_data,\n",
    "                                     train_labels,\n",
    "                                     test_data,\n",
    "                                     test_labels,\n",
    "                                     save_best_weights_path,\n",
    "                                     epochs):\n",
    "\n",
    "    acc_per_fold, loss_per_fold = [], []\n",
    "\n",
    "    # Define the K-fold Cross Validator\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "    fold_n = 1\n",
    "    for train, test in kfold.split(train_data, train_labels):\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_n} ...')\n",
    "\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath= f'Z:/Master I/PML - Practical Machine Learning/Jiani/checkpoints/model_my_cnn/{fold_n}/best_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose = True)\n",
    "\n",
    "        def scheduler_50_epochs(epoch, lr):\n",
    "            if epoch < 20:\n",
    "                return lr\n",
    "            elif epoch < 30:\n",
    "                return lr * tf.math.exp(-0.1)\n",
    "            elif epoch <= 50:\n",
    "                return lr * tf.math.exp(-0.01)\n",
    "            else :\n",
    "                return lr\n",
    "\n",
    "        lr_schedule_callback = tf.keras.callbacks.LearningRateScheduler(scheduler_50_epochs)\n",
    "\n",
    "        # callback to save tensorboard logs for later visualization\n",
    "        log_dir = \"Z:/Master I/PML - Practical Machine Learning/Jiani/checkpoints/model_my_cnn/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "        # Fit data to model\n",
    "        history = model.fit(train_images[train], train_labels[train],\n",
    "                            initial_epoch=0,\n",
    "                            batch_size=32,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=[train_images[test], train_labels[test]],\n",
    "                            callbacks=[lr_schedule_callback, model_checkpoint_callback,tensorboard_callback])\n",
    "\n",
    "        # Generate generalization metrics\n",
    "        # model.load_weights(f'Z:/Master I/PML - Practical Machine Learning/Jiani/checkpoints/model_my_cnn/{fold_n}/best_checkpoint.ckpt')\n",
    "\n",
    "        model = load_model(f\"Z:/Master I/PML - Practical Machine Learning/Jiani/checkpoints/model_my_cnn/{fold_n}/best_model.h5\")\n",
    "        scores = model.evaluate(train_images[test], train_labels[test], verbose=0)\n",
    "        print(f'Score for fold {fold_n}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_n += 1\n",
    "\n",
    "    # == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, len(acc_per_fold)):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "        print('------------------------------------------------------------------------')\n",
    "        # test_loss, test_metrics = model.evaluate(test_data, test_labels, verbose=1) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data is of shape: (112799, 28, 28, 1)\n",
      "Train labels is of shape: (112799, 1)\n",
      "Test data is of shape: (18799, 28, 28, 1)\n",
      "Test labels is of shape: (18799, 1)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 26, 26, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 13, 13, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 11, 11, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 11, 11, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 9, 9, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 9, 9, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 47)                12079     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,236,015\n",
      "Trainable params: 1,235,119\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "2818/2820 [============================>.] - ETA: 0s - loss: 0.8357 - accuracy: 0.7447\n",
      "Epoch 1: val_accuracy improved from -inf to 0.82660, saving model to Z:/Master I/PML - Practical Machine Learning/Jiani/checkpoints/model_my_cnn/1\\best_model.h5\n",
      "2820/2820 [==============================] - 78s 25ms/step - loss: 0.8357 - accuracy: 0.7447 - val_loss: 0.5043 - val_accuracy: 0.8266 - lr: 0.0010\n",
      "Epoch 2/50\n",
      " 310/2820 [==>...........................] - ETA: 53s - loss: 0.5094 - accuracy: 0.8329"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[0;32m     18\u001b[0m \u001b[39m# train \u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m train_cross_fold_save_best_model(model,\n\u001b[0;32m     20\u001b[0m                                  train_images,\n\u001b[0;32m     21\u001b[0m                                  train_labels,\n\u001b[0;32m     22\u001b[0m                                  test_images,\n\u001b[0;32m     23\u001b[0m                                  test_labels,\n\u001b[0;32m     24\u001b[0m                                  \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     25\u001b[0m                                  \u001b[39m50\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[51], line 43\u001b[0m, in \u001b[0;36mtrain_cross_fold_save_best_model\u001b[1;34m(model, train_data, train_labels, test_data, test_labels, save_best_weights_path, epochs)\u001b[0m\n\u001b[0;32m     40\u001b[0m tensorboard_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(log_dir\u001b[39m=\u001b[39mlog_dir, histogram_freq\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[39m# Fit data to model\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_images[train], train_labels[train],\n\u001b[0;32m     44\u001b[0m                     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     45\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m     46\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     47\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m[train_images[test], train_labels[test]],\n\u001b[0;32m     48\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[lr_schedule_callback, model_checkpoint_callback,tensorboard_callback])\n\u001b[0;32m     50\u001b[0m \u001b[39m# Generate generalization metrics\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39m# model.load_weights(f'Z:/Master I/PML - Practical Machine Learning/Jiani/checkpoints/model_my_cnn/{fold_n}/best_checkpoint.ckpt')\u001b[39;00m\n\u001b[0;32m     53\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mZ:/Master I/PML - Practical Machine Learning/Jiani/checkpoints/model_my_cnn/\u001b[39m\u001b[39m{\u001b[39;00mfold_n\u001b[39m}\u001b[39;00m\u001b[39m/best_model.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mz:\\anaconda3\\envs\\tf_det\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_images, train_labels, test_images, test_labels = get_emnist_data('Z:/Master I/PML - Practical Machine Learning/Jiani/data')\n",
    "\n",
    "# create model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "metrics=['accuracy',]\n",
    "\n",
    "model = get_model(\"cnn\",\n",
    "                  optimizer,\n",
    "                  loss_fn,\n",
    "                  metrics,\n",
    "                  47,\n",
    "                  used_input_shape=(28, 28, 1),\n",
    "                  trainable = False)\n",
    "model.summary()\n",
    "\n",
    "# train \n",
    "train_cross_fold_save_best_model(model,\n",
    "                                 train_images,\n",
    "                                 train_labels,\n",
    "                                 test_images,\n",
    "                                 test_labels,\n",
    "                                 \"\",\n",
    "                                 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load best CNN model and save in the tflite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 26, 26, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 13, 13, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 11, 11, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 11, 11, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 9, 9, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 9, 9, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 47)                12079     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,236,015\n",
      "Trainable params: 1,235,119\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\test\\AppData\\Local\\Temp\\tmpmg8h53pr\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\test\\AppData\\Local\\Temp\\tmpmg8h53pr\\assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "fold_n = 1\n",
    "\n",
    "model = load_model(f\"Jiani/checkpoints/model_my_cnn/{fold_n}/best_model.h5\")\n",
    "model.summary()\n",
    "\n",
    "save_name = \"my_cnn_best_model\"\n",
    "save_model_as_tflite_file(model,f\"Jiani/checkpoints/model_my_cnn/{fold_n}/\",save_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NL-CNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method used to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from : https://github.com/radu-dogaru/NL-CNN-a-compact-fast-trainable-convolutional-neural-net/blob/main/nl_cnn_demos.ipynb\n",
    "\n",
    "# NL_CNN MODEL \n",
    "# Returns a precompiled model with a specific optimizer included \n",
    "#==============================================================================================\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers  import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, SeparableConv2D  # straturi convolutionale si max-pooling \n",
    "from tensorflow.keras.optimizers import  SGD, Adadelta, Adam, Nadam\n",
    "\n",
    "\n",
    "def create_nl_cnn_model(input_shape, num_classes, k=1.5,separ=0, flat=0, width=80, nl=(3,2), add_layer=0):\n",
    "  # Arguments: k - multiplication coefficient \n",
    "  # Structure parameteres \n",
    "  kfil=k\n",
    "  filtre1=width ; filtre2=int(kfil*filtre1) ; filtre3=(kfil*filtre2)  # filters (kernels) per each layer - efic. pe primul \n",
    "  nr_conv=3 # 0, 1, 2 sau 3  (number of convolution layers)\n",
    "  csize1=3; csize2=3 ; csize3=3      # convolution kernel size (square kernel) \n",
    "  psize1=4; psize2=4 ; psize3=4      # pooling size (square)\n",
    "  str1=2; str2=2; str3=2             # stride pooling (downsampling rate) \n",
    "  pad='same'; # padding style ('valid' is also an alternative)\n",
    "  nonlinlayers1=nl[0]  # total of layers (with RELU nonlin) in the first maxpool layer  # De parametrizat asta \n",
    "  nonlinlayers2=nl[1]  # \n",
    "\n",
    "  nonlin_type='relu' # may be other as well 'tanh' 'elu' 'softsign'\n",
    "  bndrop=1 # include BatchNorm inainte de MaxPool si drop(0.3) dupa .. \n",
    "  cvdrop=1 # droput \n",
    "  drop_cv=0.5\n",
    "  \n",
    "  model = Sequential()\n",
    "  # convolution layer1  ==========================================================================\n",
    "  # Initially first layer was always a Conv2D one\n",
    "  if separ==1:\n",
    "    model.add( SeparableConv2D(filtre1, padding=pad, kernel_size=(csize1, csize1), input_shape=input_shape) )\n",
    "  elif separ==0: \n",
    "    model.add( Conv2D(filtre1, padding=pad, kernel_size=(csize1, csize1), input_shape=input_shape) )\n",
    "\n",
    "  # next are the additional layers \n",
    "  for nl in range(nonlinlayers1-1):\n",
    "    model.add(Activation(nonlin_type))  # Activ NL-CNN-1\n",
    "    if separ==1:\n",
    "      model.add(SeparableConv2D(filtre1, padding=pad, kernel_size=(csize1, csize1) ) ) # Activ NL-CNN-2\n",
    "    elif separ==0:\n",
    "      model.add(Conv2D(filtre1, padding=pad, kernel_size=(csize1, csize1)) ) # Activ NL-CNN-2\n",
    "  #  MaxPool in the end of the module \n",
    "  if bndrop==1:\n",
    "    model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(psize1, psize1),strides=(str1,str1),padding=pad))\n",
    "  if cvdrop==1:\n",
    "    model.add(Dropout(drop_cv))\n",
    "  \n",
    "  # NL LAYER 2 =======================================================================================================\n",
    " \n",
    "  if separ==1:\n",
    "    model.add(SeparableConv2D(filtre2, padding=pad, kernel_size=(csize2, csize2)) )\n",
    "  elif separ==0:\n",
    "    model.add(Conv2D(filtre2, padding=pad, kernel_size=(csize2, csize2)) )\n",
    "  # aici se adauga un neliniar \n",
    "    \n",
    "  #=========== unul extra NL=2 pe strat 2 =====================\n",
    "  for nl in range(nonlinlayers2-1):\n",
    "    model.add(Activation(nonlin_type))  # Activ NL-CNN-1\n",
    "    if separ==1:\n",
    "        model.add(SeparableConv2D(filtre2, padding=pad, kernel_size=(csize2, csize2)) ) # Activ NL-CNN-2\n",
    "    elif separ==0:\n",
    "        model.add(Conv2D(filtre2, padding=pad, kernel_size=(csize2, csize2)) ) # Activ NL-CNN-2\n",
    "        \n",
    "  # OUTPUT OF LAYER 2 (MAX-POOL)\n",
    "  if bndrop==1:\n",
    "      model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(psize2, psize2),strides=(str2,str2),padding=pad))\n",
    "  if cvdrop==1:\n",
    "      model.add(Dropout(drop_cv))\n",
    "  #-------------------------------------------------------------------------------------------\n",
    "  # LAYER 3 \n",
    "      \n",
    "  if separ==1:\n",
    "      model.add(SeparableConv2D(filtre3, padding=pad, kernel_size=(csize3, csize3)) )  # SeparableConv\n",
    "  elif separ==0:\n",
    "      model.add(Conv2D(filtre3, padding=pad, kernel_size=(csize3, csize3)) ) # Activ NL-CNN-2\n",
    "  # OUTPUT OF LAYER 3 \n",
    "  if bndrop==1:\n",
    "      model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(psize3, psize3),strides=(str3,str3),padding=pad))\n",
    "  if cvdrop==1:\n",
    "      model.add(Dropout(drop_cv))\n",
    "  #------------------- \n",
    "  # \n",
    "  # LAYER 4  (only if requested - for large images ?? )\n",
    "  if add_layer==1:    \n",
    "    if separ==1:\n",
    "      model.add(SeparableConv2D(1.2*filtre3, padding=pad, kernel_size=(csize3, csize3)) )  # SeparableConv\n",
    "    elif separ==0:\n",
    "      model.add(Conv2D(1.2*filtre3, padding=pad, kernel_size=(csize3, csize3)) ) # Activ NL-CNN-2\n",
    "    # OUTPUT OF LAYER 4\n",
    "    if bndrop==1:\n",
    "      model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(psize3, psize3),strides=(str3,str3),padding=pad))\n",
    "    if cvdrop==1:\n",
    "      model.add(Dropout(drop_cv))\n",
    "  #========================================================================================\n",
    "  # INPUT TO DENSE LAYER (FLATTEN - more data can overfit / GLOBAL - less data - may be a good choice ) \n",
    "  if flat==1:\n",
    "      model.add(Flatten())  # \n",
    "  elif flat==0:\n",
    "      model.add(GlobalAveragePooling2D()) # Global average \n",
    "   \n",
    "  model.add(Dense(num_classes, activation='softmax'))\n",
    "  # END OF MODEL DESCRIPTION \n",
    "  # ------------------ COMPILE THE MODEL\n",
    "  myopt = Adam()\n",
    "  #myopt = Nadam()\n",
    "  if separ==1:\n",
    "    myopt = RMSprop(lr=0.01) \n",
    "    #myopt = Adam(lr=0.05)\n",
    "\n",
    "  # --------------------------   LOSS function  ------------------------------------\n",
    "  my_loss='categorical_crossentropy'\n",
    "  model.compile(loss=my_loss, \n",
    "              optimizer=myopt,   \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_images, train_labels, test_images, test_labels = get_emnist_data()\n",
    "\n",
    "# create data generators\n",
    "train_gen = DataGenerator(train_images,\n",
    "                          train_labels,\n",
    "                          32,\n",
    "                          (32,32),\n",
    "                          True)\n",
    "test_gen = DataGenerator(test_images,\n",
    "                         test_labels,\n",
    "                         32,\n",
    "                         (32,32),\n",
    "                          True)\n",
    "\n",
    "# create model\n",
    "model = create_nl_cnn_model((32, 32, 3), 47, k=2, separ=0, flat=1, width=40, nl=(2,2), add_layer=0)\n",
    "model.summary()\n",
    "\n",
    "# create necessary checkpoints\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath= f'Jiani/checkpoints/nl_cnn/best_model.h5',\n",
    "                                            monitor='val_accuracy',\n",
    "                                            mode='max',\n",
    "                                            save_best_only=True,\n",
    "                                            verbose = True)\n",
    "\n",
    "# callback to save tensorboard logs for later visualization\n",
    "log_dir = \"Z:/Master I/PML - Practical Machine Learning/Jiani/checkpoints/nl_cnn/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# train\n",
    "history = model.fit(train_gen,\n",
    "                    epochs=100,\n",
    "                    validation_data=test_gen,\n",
    "                    callbacks=[model_checkpoint_callback, tensorboard_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load best NL-CNN model and save in the tflite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 40)        1120      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32, 32, 40)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 32, 32, 40)        14440     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32, 32, 40)       160       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 16, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16, 16, 40)        0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 16, 16, 80)        28880     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 16, 16, 80)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 16, 16, 80)        57680     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 16, 80)       320       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 8, 8, 80)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 8, 8, 80)          0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 8, 8, 160)         115360    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 8, 8, 160)        640       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 4, 4, 160)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 4, 4, 160)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 47)                120367    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 338,967\n",
      "Trainable params: 338,407\n",
      "Non-trainable params: 560\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\test\\AppData\\Local\\Temp\\tmps55b9f_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\test\\AppData\\Local\\Temp\\tmps55b9f_0\\assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"Jiani/checkpoints/nl_cnn/best_model.h5\")\n",
    "model.summary()\n",
    "\n",
    "save_name = \"nl_cnn_best_model\"\n",
    "save_model_as_tflite_file(model,\"Jiani/checkpoints/nl_cnn/\",save_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data is of shape: (100000, 28, 28, 1)\n",
      "Train labels is of shape: (100000, 1)\n",
      "Test data is of shape: (12799, 28, 28, 1)\n",
      "Test labels is of shape: (12799, 1)\n",
      "400/400 [==============================] - 4s 8ms/step - loss: 0.5183 - accuracy: 0.8798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading dataset = emnist\n",
      "WARNING:root:Please cite the following paper when using or referencing this Extra Keras Dataset:\n",
      "WARNING:root:Cohen, G., Afshar, S., Tapson, J., & van Schaik, A. (2017). EMNIST: an extension of MNIST to handwritten letters. Retrieved from http://arxiv.org/abs/1702.05373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data is of shape: (112800, 28, 28, 1)\n",
      "Train labels is of shape: (112800,)\n",
      "Test data is of shape: (18800, 28, 28, 1)\n",
      "Test labels is of shape: (18800,)\n",
      "588/588 [==============================] - 13s 21ms/step - loss: 1.4008 - accuracy: 0.6063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading dataset = emnist\n",
      "WARNING:root:Please cite the following paper when using or referencing this Extra Keras Dataset:\n",
      "WARNING:root:Cohen, G., Afshar, S., Tapson, J., & van Schaik, A. (2017). EMNIST: an extension of MNIST to handwritten letters. Retrieved from http://arxiv.org/abs/1702.05373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data is of shape: (112800, 28, 28, 1)\n",
      "Train labels is of shape: (112800,)\n",
      "Test data is of shape: (18800, 28, 28, 1)\n",
      "Test labels is of shape: (18800,)\n",
      "588/588 [==============================] - 13s 20ms/step - loss: 0.4131 - accuracy: 0.8881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading dataset = emnist\n",
      "WARNING:root:Please cite the following paper when using or referencing this Extra Keras Dataset:\n",
      "WARNING:root:Cohen, G., Afshar, S., Tapson, J., & van Schaik, A. (2017). EMNIST: an extension of MNIST to handwritten letters. Retrieved from http://arxiv.org/abs/1702.05373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data is of shape: (112800, 28, 28, 1)\n",
      "Train labels is of shape: (112800,)\n",
      "Test data is of shape: (18800, 28, 28, 1)\n",
      "Test labels is of shape: (18800,)\n",
      "588/588 [==============================] - 6s 9ms/step - loss: 0.2908 - accuracy: 0.9021\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"cnn\",\"mobilenet_nottrainable\", \"mobilenet_trainable\", \"nl_cnn\"]\n",
    "\n",
    "losses = []\n",
    "acc = []\n",
    "model_name = []\n",
    "\n",
    "for index, model in enumerate(model_names):\n",
    "    if model==\"cnn\":\n",
    "        train_images, train_labels, test_images, test_labels = get_emnist_data('Z:/Master I/PML - Practical Machine Learning/Jiani/data/emnist-balanced-train.csv')\n",
    "        # folds = range(1,6)\n",
    "        folds = [1]\n",
    "        for fold in folds:\n",
    "            model = load_model(os.path.join(\"Z:/Master I/PML - Practical Machine Learning/Jiani/checkpoints_jiani\",model_names[index],f\"{fold}/best_model.h5\"))\n",
    "            loss, ac = model.evaluate(test_images, test_labels)\n",
    "            losses.append(loss)\n",
    "            acc.append(ac)\n",
    "            model_name.append(\"cnn\"+f\"_fold_{fold}\")\n",
    "    else:\n",
    "        train_images, train_labels, test_images, test_labels = get_emnist_data()\n",
    "\n",
    "        test_gen = DataGenerator(test_images,\n",
    "                                 test_labels,\n",
    "                                 32,\n",
    "                                 (32,32),\n",
    "                                  True)\n",
    "        \n",
    "        model = load_model(os.path.join(\"Z:/Master I/PML - Practical Machine Learning/Jiani/checkpoints_jiani\",model_names[index],\"best_model.h5\"))\n",
    "        loss, ac = model.evaluate(test_gen)\n",
    "        losses.append(loss)\n",
    "        acc.append(ac)\n",
    "        model_name.append(model_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model_name      loss  accuracy\n",
      "0              cnn_fold_1  0.518292  0.879834\n",
      "1  mobilenet_nottrainable  1.400829  0.606330\n",
      "2     mobilenet_trainable  0.413101  0.888085\n",
      "3                  nl_cnn  0.290777  0.902074\n"
     ]
    }
   ],
   "source": [
    "column_names = ['model_name', 'loss', 'accuracy']\n",
    "\n",
    "# Create a dictionary from the lists\n",
    "metrics = {\n",
    "    'model_name': model_name,\n",
    "    'loss': losses,\n",
    "    'accuracy': acc\n",
    "}\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame(metrics,\n",
    "                  columns=column_names)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_det",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
